---
layout: post
title: "Asyncio Eventloop Optimization"
date: 2025-11-10
categories: [Technology, Python]
tags: [python, asyncio, optimization]
series: Python-Essential
published: true
excerpt: "Python asyncio ì´ë²¤íŠ¸ ë£¨í”„ì˜ ì‘ë™ ì›ë¦¬ë¥¼ ì´í•´í•˜ê³ , ë™ì‹œì„± ì²˜ë¦¬ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ìµœì í™” ê¸°ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì‹¤ì „ ì›¹ í¬ë¡¤ëŸ¬ ìµœì í™” í”„ë¡œì íŠ¸ í¬í•¨."
---

## ì†Œê°œ

Python asyncioëŠ” ë‹¨ì¼ ìŠ¤ë ˆë“œì—ì„œ ìˆ˜ì²œ ê°œì˜ ë™ì‹œ ì—°ê²°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë° í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. íŠ¹íˆ I/O ë°”ìš´ë“œ ì‘ì—…ì´ ë§ì€ ì›¹ ì„œë²„, API í´ë¼ì´ì–¸íŠ¸, í¬ë¡¤ëŸ¬ ë“±ì—ì„œ íƒì›”í•œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.

<div class="post-summary-box" markdown="1">

**ì´ ê¸€ì—ì„œ ë°°ìš¸ ë‚´ìš©**

- **Event Loop ì‘ë™ ì›ë¦¬**: asyncioì˜ í•µì‹¬ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ê¹Šì´ ì´í•´í•˜ê¸°
- **Task ìŠ¤ì¼€ì¤„ë§ ìµœì í™”**: TaskGroup, ì·¨ì†Œ ì²˜ë¦¬, ë°±í”„ë ˆì…” ì œì–´ë¥¼ í†µí•œ ì•ˆì •ì ì¸ ë™ì‹œì„± ê´€ë¦¬
- **ë™ì‹œì„± ì œì–´ íŒ¨í„´**: Semaphore, Lock, Queueë¥¼ í™œìš©í•œ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬
- **uvloop í™œìš©**: CPython ëŒ€ë¹„ 2-4ë°° ë¹ ë¥¸ ê³ ì„±ëŠ¥ ì´ë²¤íŠ¸ ë£¨í”„ ì‚¬ìš©í•˜ê¸°
- **ëŒ€ê·œëª¨ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬**: 10ë§Œ ê°œ ìš”ì²­ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì‹¤ì „ íŒ¨í„´
- **ì‹¤ì „ í”„ë¡œì íŠ¸**: ì›¹ í¬ë¡¤ëŸ¬ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ìµœì í™”í•˜ì—¬ 10ë°° ì´ìƒì˜ ì„±ëŠ¥ í–¥ìƒ ë‹¬ì„±

**í•µì‹¬ ì„±ê³¼**: 10ë§Œ ìš”ì²­ ì²˜ë¦¬ - ì¼ë°˜: 250ì´ˆ â†’ uvloop: 85ì´ˆ (2.9ë°° í–¥ìƒ)

</div>

ì´ ê¸€ì—ì„œëŠ” ë‹¤ìŒ í•µì‹¬ ê¸°ë²•ë“¤ì„ ì‹¤ìŠµ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤:

- **Event Loop ì´í•´**: ë¹„ë™ê¸° ì‹¤í–‰ì˜ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜
- **Task ê´€ë¦¬**: íš¨ìœ¨ì ì¸ ì½”ë£¨í‹´ ìŠ¤ì¼€ì¤„ë§ê³¼ ì·¨ì†Œ
- **ë™ì‹œì„± ì œì–´**: ë¦¬ì†ŒìŠ¤ ì œí•œê³¼ ë°±í”„ë ˆì…” ì²˜ë¦¬
- **ìµœì í™” íŒ¨í„´**: Connection pooling, batching, timeout
- **ì‹¤ì „ ìµœì í™”**: ì›¹ í¬ë¡¤ëŸ¬ ì„±ëŠ¥ ê°œì„  ì‚¬ë¡€

```mermaid
graph TD
    A[Asyncio ìµœì í™”] --> B[Event Loop<br/>ì´í•´]
    A --> C[Task<br/>ê´€ë¦¬]
    A --> D[ë™ì‹œì„±<br/>ì œì–´]
    A --> E[ìµœì í™”<br/>íŒ¨í„´]

    B --> B1[ì‘ë™ ì›ë¦¬]
    B --> B2[ìŠ¤ì¼€ì¤„ë§]

    C --> C1[Task ìƒì„±]
    C --> C2[ì·¨ì†Œ ì²˜ë¦¬]
    C --> C3[ì˜ˆì™¸ ê´€ë¦¬]

    D --> D1[Semaphore]
    D --> D2[Lock/Event]
    D --> D3[Queue]

    E --> E1[Connection Pool]
    E --> E2[Batching]
    E --> E3[Timeout]

    style B fill:#e1f5ff
    style C fill:#fff4e1
    style D fill:#e8f5e9
    style E fill:#ffe1f5
```

## 1. Event Loop: Asyncioì˜ í•µì‹¬

Event loopëŠ” asyncioì˜ ì‹¬ì¥ë¶€ë¡œ, ë¹„ë™ê¸° ì‘ì—…ë“¤ì„ ìŠ¤ì¼€ì¤„ë§í•˜ê³  ì‹¤í–‰í•˜ëŠ” ì¤‘ì•™ ê´€ë¦¬ìì…ë‹ˆë‹¤.

### Event Loop ê¸°ë³¸ ê°œë…

```python
import asyncio
import time

async def task1():
    print("Task 1 ì‹œì‘")
    await asyncio.sleep(1)
    print("Task 1 ì™„ë£Œ")
    return "Result 1"

async def task2():
    print("Task 2 ì‹œì‘")
    await asyncio.sleep(0.5)
    print("Task 2 ì™„ë£Œ")
    return "Result 2"

async def main():
    # ë™ì‹œì— ë‘ íƒœìŠ¤í¬ ì‹¤í–‰
    start = time.time()
    results = await asyncio.gather(task1(), task2())
    elapsed = time.time() - start

    print(f"ê²°ê³¼: {results}")
    print(f"ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")

# ì‹¤í–‰
asyncio.run(main())
```

**ì¶œë ¥ ì˜ˆì‹œ:**

```
Task 1 ì‹œì‘
Task 2 ì‹œì‘
Task 2 ì™„ë£Œ
Task 1 ì™„ë£Œ
ê²°ê³¼: ['Result 1', 'Result 2']
ì†Œìš” ì‹œê°„: 1.00ì´ˆ
```

### Event Loop ì‘ë™ ì›ë¦¬

```mermaid
sequenceDiagram
    participant App as Application
    participant ELoop as Event Loop
    participant Task1 as Task 1
    participant Task2 as Task 2
    participant IO as I/O

    App->>ELoop: asyncio.run(main())
    ELoop->>Task1: ì½”ë£¨í‹´ ìŠ¤ì¼€ì¤„
    ELoop->>Task2: ì½”ë£¨í‹´ ìŠ¤ì¼€ì¤„

    Task1->>IO: await asyncio.sleep(1)
    Note right of Task1: ëŒ€ê¸° ìƒíƒœ

    Task2->>IO: await asyncio.sleep(0.5)
    Note right of Task2: ëŒ€ê¸° ìƒíƒœ

    IO-->>Task2: 0.5ì´ˆ í›„ ì™„ë£Œ
    Task2-->>ELoop: ê²°ê³¼ ë°˜í™˜

    IO-->>Task1: 1ì´ˆ í›„ ì™„ë£Œ
    Task1-->>ELoop: ê²°ê³¼ ë°˜í™˜

    ELoop-->>App: ëª¨ë“  ê²°ê³¼ ë°˜í™˜
```

### Event Loop ì ‘ê·¼ ë° ì œì–´

```python
import asyncio

async def inspect_event_loop():
    # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ event loop ê°€ì ¸ì˜¤ê¸°
    loop = asyncio.get_running_loop()

    print(f"Event Loop: {loop}")
    print(f"Is running: {loop.is_running()}")
    print(f"Is closed: {loop.is_closed()}")

    # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ íƒœìŠ¤í¬ í™•ì¸
    current_task = asyncio.current_task()
    print(f"Current task: {current_task.get_name()}")

    # ëª¨ë“  íƒœìŠ¤í¬ ì¡°íšŒ
    all_tasks = asyncio.all_tasks()
    print(f"Total tasks: {len(all_tasks)}")
    for task in all_tasks:
        print(f"  - {task.get_name()}: {task}")

asyncio.run(inspect_event_loop())
```

## 2. Task ê´€ë¦¬ ë° ìŠ¤ì¼€ì¤„ë§

íš¨ìœ¨ì ì¸ Task ê´€ë¦¬ëŠ” asyncio ì„±ëŠ¥ì˜ í•µì‹¬ì…ë‹ˆë‹¤.

### Task ìƒì„± ë° ê´€ë¦¬

```python
import asyncio
import time

async def fetch_data(url, delay):
    """ê°€ìƒì˜ ë°ì´í„° fetch í•¨ìˆ˜"""
    print(f"[{time.strftime('%H:%M:%S')}] Fetching {url}")
    await asyncio.sleep(delay)
    print(f"[{time.strftime('%H:%M:%S')}] Completed {url}")
    return f"Data from {url}"

async def task_creation_patterns():
    # ë°©ë²• 1: create_taskë¡œ ì¦‰ì‹œ ìŠ¤ì¼€ì¤„
    task1 = asyncio.create_task(
        fetch_data("https://api1.com", 1),
        name="API-1"
    )

    task2 = asyncio.create_task(
        fetch_data("https://api2.com", 0.5),
        name="API-2"
    )

    # ë°©ë²• 2: gatherë¡œ ì—¬ëŸ¬ ì½”ë£¨í‹´ ë™ì‹œ ì‹¤í–‰
    results = await asyncio.gather(task1, task2)
    print(f"Results: {results}")

asyncio.run(task_creation_patterns())
```

**ì¶œë ¥ ì˜ˆì‹œ:**

```
[14:30:15] Fetching https://api1.com
[14:30:15] Fetching https://api2.com
[14:30:15] Completed https://api2.com
[14:30:16] Completed https://api1.com
Results: ['Data from https://api1.com', 'Data from https://api2.com']
```

### Task ì·¨ì†Œ ë° íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬

```python
import asyncio

async def long_running_task():
    """ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” ì‘ì—…"""
    try:
        print("ì‘ì—… ì‹œì‘...")
        await asyncio.sleep(10)
        print("ì‘ì—… ì™„ë£Œ")
        return "Success"
    except asyncio.CancelledError:
        print("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤")
        # ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
        raise  # ë°˜ë“œì‹œ re-raise í•´ì•¼ í•¨

async def task_cancellation_example():
    # Task ì·¨ì†Œ ì˜ˆì œ
    task = asyncio.create_task(long_running_task())

    await asyncio.sleep(2)
    task.cancel()

    try:
        await task
    except asyncio.CancelledError:
        print("Taskê°€ ì„±ê³µì ìœ¼ë¡œ ì·¨ì†Œë¨")

async def timeout_example():
    """íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ ì˜ˆì œ"""
    try:
        # 3ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
        result = await asyncio.wait_for(
            long_running_task(),
            timeout=3.0
        )
        print(f"ê²°ê³¼: {result}")
    except asyncio.TimeoutError:
        print("ì‘ì—…ì´ íƒ€ì„ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤")

# ì‹¤í–‰
print("=== Task ì·¨ì†Œ ì˜ˆì œ ===")
asyncio.run(task_cancellation_example())

print("\n=== íƒ€ì„ì•„ì›ƒ ì˜ˆì œ ===")
asyncio.run(timeout_example())
```

### ì˜ˆì™¸ ì²˜ë¦¬ íŒ¨í„´

```python
import asyncio

async def task_with_error(task_id):
    """ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ëŠ” íƒœìŠ¤í¬"""
    await asyncio.sleep(0.1)
    if task_id == 2:
        raise ValueError(f"Task {task_id} failed")
    return f"Task {task_id} success"

async def exception_handling_patterns():
    # íŒ¨í„´ 1: gather with return_exceptions=True
    print("=== íŒ¨í„´ 1: gather with return_exceptions ===")
    results = await asyncio.gather(
        task_with_error(1),
        task_with_error(2),
        task_with_error(3),
        return_exceptions=True
    )

    for i, result in enumerate(results, 1):
        if isinstance(result, Exception):
            print(f"Task {i} failed: {result}")
        else:
            print(f"Task {i}: {result}")

    # íŒ¨í„´ 2: ê°œë³„ Task ì˜ˆì™¸ ì²˜ë¦¬
    print("\n=== íŒ¨í„´ 2: ê°œë³„ Task ì˜ˆì™¸ ì²˜ë¦¬ ===")
    tasks = [
        asyncio.create_task(task_with_error(i))
        for i in range(1, 4)
    ]

    for task in asyncio.as_completed(tasks):
        try:
            result = await task
            print(f"Success: {result}")
        except ValueError as e:
            print(f"Error: {e}")

asyncio.run(exception_handling_patterns())
```

### TaskGroup: êµ¬ì¡°í™”ëœ ë™ì‹œì„± (Python 3.11+)

TaskGroupì€ ê´€ë ¨ëœ ì‘ì—…ë“¤ì„ ê·¸ë£¹ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ìë™ìœ¼ë¡œ ì •ë¦¬í•˜ëŠ” ê°•ë ¥í•œ ê¸°ëŠ¥ì…ë‹ˆë‹¤.

```python
import asyncio

async def fetch_data(url_id, should_fail=False):
    """ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì‘ì—…"""
    await asyncio.sleep(0.5)
    if should_fail:
        raise ValueError(f"Failed to fetch {url_id}")
    return f"Data from {url_id}"

async def taskgroup_basic():
    """TaskGroup ê¸°ë³¸ ì‚¬ìš©ë²•"""
    async with asyncio.TaskGroup() as tg:
        task1 = tg.create_task(fetch_data(1))
        task2 = tg.create_task(fetch_data(2))
        task3 = tg.create_task(fetch_data(3))

    # TaskGroup ë¸”ë¡ì„ ë²—ì–´ë‚˜ë©´ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë¨ì´ ë³´ì¥ë¨
    print(f"ëª¨ë“  ì‘ì—… ì™„ë£Œ:")
    print(f"  Task 1: {task1.result()}")
    print(f"  Task 2: {task2.result()}")
    print(f"  Task 3: {task3.result()}")

async def taskgroup_exception_handling():
    """TaskGroup ì˜ˆì™¸ ì²˜ë¦¬"""
    try:
        async with asyncio.TaskGroup() as tg:
            tg.create_task(fetch_data(1))
            tg.create_task(fetch_data(2, should_fail=True))  # ì‹¤íŒ¨
            tg.create_task(fetch_data(3))

    except* ValueError as eg:
        # ExceptionGroupìœ¼ë¡œ ëª¨ë“  ì˜ˆì™¸ë¥¼ ë°›ìŒ
        print(f"ì‘ì—… ì¤‘ {len(eg.exceptions)}ê°œ ì‹¤íŒ¨:")
        for exc in eg.exceptions:
            print(f"  - {exc}")

# Python 3.11+ ì—ì„œë§Œ ì‹¤í–‰ ê°€ëŠ¥
# asyncio.run(taskgroup_basic())
# asyncio.run(taskgroup_exception_handling())
```

### ê³ ê¸‰ Cancellation íŒ¨í„´

```python
import asyncio
import signal

class GracefulShutdown:
    """ìš°ì•„í•œ ì¢…ë£Œë¥¼ ìœ„í•œ í—¬í¼ í´ë˜ìŠ¤"""

    def __init__(self):
        self.shutdown_event = asyncio.Event()
        self.tasks = set()

    def register_task(self, task):
        """ì·¨ì†Œ ê°€ëŠ¥í•œ ì‘ì—… ë“±ë¡"""
        self.tasks.add(task)
        task.add_done_callback(self.tasks.discard)

    async def shutdown(self):
        """ëª¨ë“  ì‘ì—… ì•ˆì „í•˜ê²Œ ì¢…ë£Œ"""
        print(f"\nì¢…ë£Œ ì‹ í˜¸ ë°›ìŒ. {len(self.tasks)}ê°œ ì‘ì—… ì •ë¦¬ ì¤‘...")

        # ëª¨ë“  ì‘ì—…ì— ì·¨ì†Œ ì‹ í˜¸
        for task in self.tasks:
            task.cancel()

        # ì·¨ì†Œ ì™„ë£Œ ëŒ€ê¸° (íƒ€ì„ì•„ì›ƒ í¬í•¨)
        if self.tasks:
            await asyncio.wait(self.tasks, timeout=5.0)

        print("ëª¨ë“  ì‘ì—… ì •ë¦¬ ì™„ë£Œ")

async def worker(worker_id, shutdown_handler):
    """ì·¨ì†Œ ê°€ëŠ¥í•œ ì›Œì»¤"""
    try:
        while True:
            print(f"Worker {worker_id}: ì‘ì—… ì¤‘...")
            await asyncio.sleep(1)

    except asyncio.CancelledError:
        print(f"Worker {worker_id}: ì •ë¦¬ ì‘ì—… ìˆ˜í–‰ ì¤‘...")
        await asyncio.sleep(0.5)  # ì •ë¦¬ ì‘ì—…
        print(f"Worker {worker_id}: ì •ìƒ ì¢…ë£Œ")
        raise  # ë°˜ë“œì‹œ re-raise

async def graceful_shutdown_example():
    """ìš°ì•„í•œ ì¢…ë£Œ ì˜ˆì œ"""
    shutdown_handler = GracefulShutdown()

    # ì›Œì»¤ ì‘ì—… ìƒì„± ë° ë“±ë¡
    for i in range(3):
        task = asyncio.create_task(worker(i, shutdown_handler))
        shutdown_handler.register_task(task)

    # 3ì´ˆ í›„ ì¢…ë£Œ
    await asyncio.sleep(3)
    await shutdown_handler.shutdown()

# asyncio.run(graceful_shutdown_example())
```

### Backpressure ì œì–´

BackpressureëŠ” ìƒì‚° ì†ë„ê°€ ì†Œë¹„ ì†ë„ë¥¼ ì´ˆê³¼í•  ë•Œ ì‹œìŠ¤í…œì„ ë³´í˜¸í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤.

```python
import asyncio
import time
from collections import deque

class BackpressureQueue:
    """ë°±í”„ë ˆì…” ì œì–´ë¥¼ í¬í•¨í•œ í"""

    def __init__(self, maxsize=100, high_watermark=80, low_watermark=20):
        self.queue = asyncio.Queue(maxsize=maxsize)
        self.high_watermark = high_watermark
        self.low_watermark = low_watermark
        self.producer_paused = False
        self.stats = {'produced': 0, 'consumed': 0, 'pauses': 0}

    async def put(self, item):
        """ì•„ì´í…œ ì¶”ê°€ (ë°±í”„ë ˆì…” ì ìš©)"""
        # High watermark ë„ë‹¬ ì‹œ ì¼ì‹œ ì •ì§€
        if self.queue.qsize() >= self.high_watermark and not self.producer_paused:
            self.producer_paused = True
            self.stats['pauses'] += 1
            print(f"âš ï¸  ë°±í”„ë ˆì…”: í í¬ê¸° {self.queue.qsize()}, ìƒì‚° ì¼ì‹œ ì •ì§€")

        await self.queue.put(item)
        self.stats['produced'] += 1

        # Low watermark ì´í•˜ë¡œ ë–¨ì–´ì§€ë©´ ì¬ê°œ
        if self.queue.qsize() <= self.low_watermark and self.producer_paused:
            self.producer_paused = False
            print(f"âœ… ë°±í”„ë ˆì…” í•´ì œ: í í¬ê¸° {self.queue.qsize()}, ìƒì‚° ì¬ê°œ")

    async def get(self):
        """ì•„ì´í…œ ê°€ì ¸ì˜¤ê¸°"""
        item = await self.queue.get()
        self.stats['consumed'] += 1
        return item

    def get_stats(self):
        """í†µê³„ ë°˜í™˜"""
        return {
            **self.stats,
            'queue_size': self.queue.qsize(),
            'paused': self.producer_paused
        }

async def fast_producer(queue, count=100):
    """ë¹ ë¥¸ ìƒì‚°ì"""
    for i in range(count):
        await queue.put(f"item_{i}")
        await asyncio.sleep(0.01)  # ë¹ ë¥¸ ìƒì‚°

async def slow_consumer(queue, count=100):
    """ëŠë¦° ì†Œë¹„ì"""
    for _ in range(count):
        item = await queue.get()
        await asyncio.sleep(0.05)  # ëŠë¦° ì†Œë¹„

async def backpressure_example():
    """ë°±í”„ë ˆì…” ì œì–´ ì˜ˆì œ"""
    queue = BackpressureQueue(maxsize=100, high_watermark=80, low_watermark=20)

    # ìƒì‚°ìì™€ ì†Œë¹„ì ë™ì‹œ ì‹¤í–‰
    await asyncio.gather(
        fast_producer(queue, 100),
        slow_consumer(queue, 100)
    )

    stats = queue.get_stats()
    print(f"\ní†µê³„:")
    print(f"  ìƒì‚°: {stats['produced']}ê°œ")
    print(f"  ì†Œë¹„: {stats['consumed']}ê°œ")
    print(f"  ì¼ì‹œ ì •ì§€ íšŸìˆ˜: {stats['pauses']}íšŒ")

asyncio.run(backpressure_example())
```

**ì¶œë ¥ ì˜ˆì‹œ:**

```
âš ï¸  ë°±í”„ë ˆì…”: í í¬ê¸° 80, ìƒì‚° ì¼ì‹œ ì •ì§€
âœ… ë°±í”„ë ˆì…” í•´ì œ: í í¬ê¸° 20, ìƒì‚° ì¬ê°œ
âš ï¸  ë°±í”„ë ˆì…”: í í¬ê¸° 80, ìƒì‚° ì¼ì‹œ ì •ì§€
âœ… ë°±í”„ë ˆì…” í•´ì œ: í í¬ê¸° 18, ìƒì‚° ì¬ê°œ

í†µê³„:
  ìƒì‚°: 100ê°œ
  ì†Œë¹„: 100ê°œ
  ì¼ì‹œ ì •ì§€ íšŸìˆ˜: 2íšŒ
```

## 3. ë™ì‹œì„± ì œì–´

ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ë™ì‹œì„± ì œì–´ íŒ¨í„´ì…ë‹ˆë‹¤.

### Semaphore: ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì œí•œ

```python
import asyncio
import time

async def fetch_url(url, semaphore):
    """Semaphoreë¡œ ì œì–´ë˜ëŠ” URL fetch"""
    async with semaphore:
        print(f"[{time.strftime('%H:%M:%S')}] Fetching: {url}")
        await asyncio.sleep(1)  # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì‹œë®¬ë ˆì´ì…˜
        print(f"[{time.strftime('%H:%M:%S')}] Completed: {url}")
        return f"Data from {url}"

async def semaphore_example():
    # ë™ì‹œì— ìµœëŒ€ 3ê°œë§Œ ì‹¤í–‰
    semaphore = asyncio.Semaphore(3)

    urls = [f"https://example.com/page{i}" for i in range(10)]

    start = time.time()
    tasks = [fetch_url(url, semaphore) for url in urls]
    results = await asyncio.gather(*tasks)
    elapsed = time.time() - start

    print(f"\nì´ {len(results)}ê°œ URL ì²˜ë¦¬ ì™„ë£Œ")
    print(f"ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
    print(f"ì˜ˆìƒ ì‹œê°„ (ì œí•œ ì—†ìŒ): ~1ì´ˆ")
    print(f"ì‹¤ì œ ì‹œê°„ (3ê°œ ì œí•œ): ~{10/3:.1f}ì´ˆ")

asyncio.run(semaphore_example())
```

**ì¶œë ¥ ì˜ˆì‹œ:**

```
[14:35:20] Fetching: https://example.com/page0
[14:35:20] Fetching: https://example.com/page1
[14:35:20] Fetching: https://example.com/page2
[14:35:21] Completed: https://example.com/page0
[14:35:21] Fetching: https://example.com/page3
[14:35:21] Completed: https://example.com/page1
[14:35:21] Fetching: https://example.com/page4
...
ì´ 10ê°œ URL ì²˜ë¦¬ ì™„ë£Œ
ì†Œìš” ì‹œê°„: 4.01ì´ˆ
```

### Lockê³¼ Event

```python
import asyncio

class SharedResource:
    """ê³µìœ  ë¦¬ì†ŒìŠ¤ í´ë˜ìŠ¤"""
    def __init__(self):
        self.lock = asyncio.Lock()
        self.value = 0

    async def increment(self, worker_id):
        """Lockìœ¼ë¡œ ë³´í˜¸ë˜ëŠ” ì¦ê°€ ì—°ì‚°"""
        async with self.lock:
            current = self.value
            print(f"Worker {worker_id}: í˜„ì¬ ê°’ {current}")
            await asyncio.sleep(0.1)  # ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
            self.value = current + 1
            print(f"Worker {worker_id}: ê°’ì„ {self.value}ë¡œ ì¦ê°€")

async def lock_example():
    resource = SharedResource()

    # 5ê°œ ì›Œì»¤ê°€ ë™ì‹œì— ì ‘ê·¼
    await asyncio.gather(*[
        resource.increment(i) for i in range(5)
    ])

    print(f"ìµœì¢… ê°’: {resource.value}")

# Event ì‚¬ìš© ì˜ˆì œ
async def waiter(event, worker_id):
    """ì´ë²¤íŠ¸ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì›Œì»¤"""
    print(f"Worker {worker_id}: ì´ë²¤íŠ¸ ëŒ€ê¸° ì¤‘...")
    await event.wait()
    print(f"Worker {worker_id}: ì´ë²¤íŠ¸ ìˆ˜ì‹ ! ì‘ì—… ì‹œì‘")

async def event_example():
    event = asyncio.Event()

    # 3ê°œ ì›Œì»¤ ìƒì„±
    tasks = [
        asyncio.create_task(waiter(event, i))
        for i in range(3)
    ]

    print("2ì´ˆ í›„ ì´ë²¤íŠ¸ ë°œìƒ...")
    await asyncio.sleep(2)
    event.set()

    await asyncio.gather(*tasks)

print("=== Lock ì˜ˆì œ ===")
asyncio.run(lock_example())

print("\n=== Event ì˜ˆì œ ===")
asyncio.run(event_example())
```

### asyncio.Queue: ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´

```python
import asyncio
import random

async def producer(queue, producer_id):
    """ë°ì´í„°ë¥¼ ìƒì‚°í•˜ì—¬ íì— ë„£ìŒ"""
    for i in range(5):
        item = f"P{producer_id}-Item{i}"
        await queue.put(item)
        print(f"ìƒì‚°ì {producer_id}: {item} ìƒì‚°")
        await asyncio.sleep(random.uniform(0.1, 0.5))

async def consumer(queue, consumer_id):
    """íì—ì„œ ë°ì´í„°ë¥¼ êº¼ë‚´ ì²˜ë¦¬"""
    while True:
        item = await queue.get()
        if item is None:  # ì¢…ë£Œ ì‹ í˜¸
            queue.task_done()
            break

        print(f"  ì†Œë¹„ì {consumer_id}: {item} ì²˜ë¦¬ ì¤‘...")
        await asyncio.sleep(random.uniform(0.2, 0.6))
        print(f"  ì†Œë¹„ì {consumer_id}: {item} ì™„ë£Œ")
        queue.task_done()

async def queue_example():
    queue = asyncio.Queue(maxsize=10)

    # 2ê°œ ìƒì‚°ì, 3ê°œ ì†Œë¹„ì
    producers = [
        asyncio.create_task(producer(queue, i))
        for i in range(2)
    ]

    consumers = [
        asyncio.create_task(consumer(queue, i))
        for i in range(3)
    ]

    # ìƒì‚°ì ì™„ë£Œ ëŒ€ê¸°
    await asyncio.gather(*producers)

    # íì˜ ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    await queue.join()

    # ì†Œë¹„ì ì¢…ë£Œ
    for _ in range(3):
        await queue.put(None)

    await asyncio.gather(*consumers)
    print("ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

asyncio.run(queue_example())
```

## 4. ìµœì í™” íŒ¨í„´

ì‹¤ì „ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” asyncio ìµœì í™” íŒ¨í„´ë“¤ì…ë‹ˆë‹¤.

### Connection Pooling

```python
import asyncio
import aiohttp

class ConnectionPool:
    """ê°„ë‹¨í•œ connection pool êµ¬í˜„"""
    def __init__(self, max_connections=10):
        self.semaphore = asyncio.Semaphore(max_connections)
        self.session = None

    async def __aenter__(self):
        # aiohttp ì„¸ì…˜ ìƒì„± (connection pooling ë‚´ì¥)
        connector = aiohttp.TCPConnector(limit=10, limit_per_host=5)
        self.session = aiohttp.ClientSession(connector=connector)
        return self

    async def __aexit__(self, *args):
        await self.session.close()

    async def fetch(self, url):
        """Connection poolì„ í†µí•œ HTTP ìš”ì²­"""
        async with self.semaphore:
            async with self.session.get(url) as response:
                return await response.text()

async def connection_pool_example():
    """Connection pooling ì˜ˆì œ"""
    urls = [
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/1",
        "https://httpbin.org/delay/1",
    ] * 5  # 15ê°œ ìš”ì²­

    async with ConnectionPool(max_connections=5) as pool:
        start = time.time()
        tasks = [pool.fetch(url) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        elapsed = time.time() - start

        success = sum(1 for r in results if not isinstance(r, Exception))
        print(f"ì„±ê³µ: {success}/{len(urls)} ìš”ì²­")
        print(f"ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")

# ì£¼ì˜: ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ì„ í•˜ë¯€ë¡œ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤
# asyncio.run(connection_pool_example())
```

### Request Batching

```python
import asyncio
from typing import List

class BatchProcessor:
    """ìš”ì²­ì„ ë°°ì¹˜ë¡œ ë¬¶ì–´ ì²˜ë¦¬"""
    def __init__(self, batch_size=10, timeout=1.0):
        self.batch_size = batch_size
        self.timeout = timeout
        self.queue = asyncio.Queue()
        self.results = {}

    async def process_batch(self, items):
        """ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ì˜ˆ: ë°ì´í„°ë² ì´ìŠ¤ ì¼ê´„ ì¿¼ë¦¬)"""
        print(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {len(items)}ê°œ ì•„ì´í…œ")
        await asyncio.sleep(0.5)  # ì‹¤ì œ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
        return {item: f"processed_{item}" for item in items}

    async def worker(self):
        """ë°°ì¹˜ë¥¼ ìˆ˜ì§‘í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ì›Œì»¤"""
        while True:
            batch = []
            futures = []

            try:
                # ì²« ì•„ì´í…œ ëŒ€ê¸°
                item, future = await self.queue.get()
                batch.append(item)
                futures.append(future)

                # ë‚˜ë¨¸ì§€ ì•„ì´í…œ ìˆ˜ì§‘ (íƒ€ì„ì•„ì›ƒ ë˜ëŠ” ë°°ì¹˜ í¬ê¸°ê¹Œì§€)
                while len(batch) < self.batch_size:
                    try:
                        item, future = await asyncio.wait_for(
                            self.queue.get(),
                            timeout=self.timeout
                        )
                        batch.append(item)
                        futures.append(future)
                    except asyncio.TimeoutError:
                        break

                # ë°°ì¹˜ ì²˜ë¦¬
                results = await self.process_batch(batch)

                # ê²°ê³¼ ë°˜í™˜
                for item, future in zip(batch, futures):
                    if not future.done():
                        future.set_result(results[item])

            except Exception as e:
                for future in futures:
                    if not future.done():
                        future.set_exception(e)

    async def add_item(self, item):
        """ì•„ì´í…œì„ ë°°ì¹˜ì— ì¶”ê°€"""
        future = asyncio.Future()
        await self.queue.put((item, future))
        return await future

async def batching_example():
    """ë°°ì¹˜ ì²˜ë¦¬ ì˜ˆì œ"""
    processor = BatchProcessor(batch_size=5, timeout=0.5)

    # ì›Œì»¤ ì‹œì‘
    worker_task = asyncio.create_task(processor.worker())

    # 20ê°œ ì•„ì´í…œì„ ë¹„ë™ê¸°ë¡œ ì¶”ê°€
    tasks = [
        processor.add_item(f"item_{i}")
        for i in range(20)
    ]

    results = await asyncio.gather(*tasks)
    print(f"\nì²˜ë¦¬ ì™„ë£Œ: {len(results)}ê°œ ì•„ì´í…œ")
    print(f"ê²°ê³¼ ìƒ˜í”Œ: {results[:3]}")

    worker_task.cancel()

asyncio.run(batching_example())
```

### Timeout ê´€ë¦¬ ì „ëµ

```python
import asyncio
import time

async def resilient_fetch(url, timeout=5.0, retries=3):
    """íƒ€ì„ì•„ì›ƒê³¼ ì¬ì‹œë„ë¥¼ í¬í•¨í•œ ì•ˆì •ì ì¸ fetch"""
    for attempt in range(retries):
        try:
            print(f"ì‹œë„ {attempt + 1}/{retries}: {url}")

            async with asyncio.timeout(timeout):  # Python 3.11+
                # ë˜ëŠ”: await asyncio.wait_for(fetch(url), timeout=timeout)
                await asyncio.sleep(2 if attempt < 2 else 0.5)
                return f"Success: {url}"

        except asyncio.TimeoutError:
            print(f"  íƒ€ì„ì•„ì›ƒ! (ì‹œë„ {attempt + 1})")
            if attempt == retries - 1:
                raise
            await asyncio.sleep(1)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°

    return None

async def timeout_strategies():
    """ë‹¤ì–‘í•œ íƒ€ì„ì•„ì›ƒ ì „ëµ"""
    urls = [
        "https://fast-api.com",
        "https://slow-api.com",
        "https://very-slow-api.com",
    ]

    start = time.time()

    # ì „ëµ 1: ê°œë³„ íƒ€ì„ì•„ì›ƒ
    tasks = [resilient_fetch(url, timeout=3.0) for url in urls]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    elapsed = time.time() - start

    print(f"\nì´ ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
    for url, result in zip(urls, results):
        if isinstance(result, Exception):
            print(f"{url}: ì‹¤íŒ¨ - {result}")
        else:
            print(f"{url}: {result}")

asyncio.run(timeout_strategies())
```

## 5. ì‹¤ì „ í”„ë¡œì íŠ¸: ì›¹ í¬ë¡¤ëŸ¬ ìµœì í™”

ì‹¤ì œ ì›¹ í¬ë¡¤ëŸ¬ë¥¼ ë‹¨ê³„ì ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

### Step 1: ë™ê¸° ë°©ì‹ (ë¹„íš¨ìœ¨ì )

```python
import requests
import time

def fetch_sync(url):
    """ë™ê¸° ë°©ì‹ HTTP ìš”ì²­"""
    response = requests.get(url)
    return len(response.text)

def crawl_sync(urls):
    """ë™ê¸° ë°©ì‹ í¬ë¡¤ëŸ¬"""
    results = []
    for url in urls:
        try:
            size = fetch_sync(url)
            results.append((url, size))
        except Exception as e:
            results.append((url, f"Error: {e}"))
    return results

# í…ŒìŠ¤íŠ¸ URL ëª©ë¡
test_urls = [
    "https://httpbin.org/delay/1",
] * 10

start = time.time()
results = crawl_sync(test_urls)
sync_time = time.time() - start

print(f"ë™ê¸° ë°©ì‹: {len(results)}ê°œ URL, {sync_time:.2f}ì´ˆ")
```

### Step 2: ê¸°ë³¸ Asyncio (ê°œì„ )

```python
import asyncio
import aiohttp
import time

async def fetch_async(session, url):
    """ë¹„ë™ê¸° HTTP ìš”ì²­"""
    async with session.get(url) as response:
        text = await response.text()
        return len(text)

async def crawl_async_basic(urls):
    """ê¸°ë³¸ ë¹„ë™ê¸° í¬ë¡¤ëŸ¬"""
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_async(session, url) for url in urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        return list(zip(urls, results))

# í…ŒìŠ¤íŠ¸
start = time.time()
results = asyncio.run(crawl_async_basic(test_urls))
async_time = time.time() - start

print(f"ê¸°ë³¸ asyncio: {len(results)}ê°œ URL, {async_time:.2f}ì´ˆ")
print(f"ì†ë„ í–¥ìƒ: {sync_time / async_time:.1f}ë°°")
```

### Step 3: ìµœì í™”ëœ í¬ë¡¤ëŸ¬ (ìµœì¢…)

```python
import asyncio
import aiohttp
import time
from typing import List, Tuple

class OptimizedCrawler:
    """ìµœì í™”ëœ ì›¹ í¬ë¡¤ëŸ¬"""

    def __init__(
        self,
        max_concurrent=10,
        timeout=30,
        retry_count=3,
        rate_limit=None
    ):
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self.retry_count = retry_count
        self.rate_limit = rate_limit
        self.session = None

    async def __aenter__(self):
        connector = aiohttp.TCPConnector(
            limit=self.max_concurrent,
            limit_per_host=5,
            ttl_dns_cache=300
        )
        self.session = aiohttp.ClientSession(
            connector=connector,
            timeout=self.timeout
        )
        return self

    async def __aexit__(self, *args):
        await self.session.close()

    async def fetch_with_retry(self, url: str) -> Tuple[str, any]:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ fetch"""
        async with self.semaphore:
            for attempt in range(self.retry_count):
                try:
                    if self.rate_limit:
                        await asyncio.sleep(1.0 / self.rate_limit)

                    async with self.session.get(url) as response:
                        text = await response.text()
                        return (url, {
                            'status': response.status,
                            'size': len(text),
                            'success': True
                        })

                except asyncio.TimeoutError:
                    if attempt == self.retry_count - 1:
                        return (url, {'success': False, 'error': 'Timeout'})
                    await asyncio.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„

                except Exception as e:
                    if attempt == self.retry_count - 1:
                        return (url, {'success': False, 'error': str(e)})
                    await asyncio.sleep(1)

    async def crawl(self, urls: List[str]) -> List[Tuple[str, dict]]:
        """URL ëª©ë¡ í¬ë¡¤ë§"""
        tasks = [self.fetch_with_retry(url) for url in urls]
        results = await asyncio.gather(*tasks)
        return results

async def optimized_crawl_example():
    """ìµœì í™”ëœ í¬ë¡¤ëŸ¬ ì‚¬ìš© ì˜ˆì œ"""
    test_urls = [
        "https://httpbin.org/delay/1",
    ] * 100  # 100ê°œ URL

    async with OptimizedCrawler(
        max_concurrent=20,
        timeout=30,
        retry_count=3
    ) as crawler:
        start = time.time()
        results = await crawler.crawl(test_urls)
        elapsed = time.time() - start

        success = sum(1 for _, r in results if r.get('success'))

        print(f"\nìµœì í™”ëœ í¬ë¡¤ëŸ¬:")
        print(f"  ì²˜ë¦¬: {len(results)}ê°œ URL")
        print(f"  ì„±ê³µ: {success}ê°œ")
        print(f"  ì‹¤íŒ¨: {len(results) - success}ê°œ")
        print(f"  ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ")
        print(f"  ì´ˆë‹¹ ì²˜ë¦¬: {len(results) / elapsed:.1f} requests/sec")

# ì‹¤í–‰
# asyncio.run(optimized_crawl_example())
```

### ì„±ëŠ¥ ë¹„êµ ìš”ì•½

```mermaid
graph TD
    Start[ë™ê¸° ë°©ì‹<br/>100 URLs<br/>~100ì´ˆ] --> Step1{Asyncio<br/>ê¸°ë³¸}
    Step1 -->|10ë°° í–¥ìƒ| Mid[ê¸°ë³¸ Async<br/>~10ì´ˆ]

    Mid --> Step2{ìµœì í™”<br/>ì ìš©}
    Step2 -->|3ë°° í–¥ìƒ| End[ìµœì í™”ëœ<br/>Asyncio<br/>~3ì´ˆ]

    Start -.->|ì „ì²´ 33ë°° í–¥ìƒ| End

    style Start fill:#ffcccc
    style Mid fill:#fff9c4
    style End fill:#ccffcc
    style Step1 fill:#e1f5ff
    style Step2 fill:#e1f5ff

    Note1[ë™ì‹œì„± ì œì–´<br/>Connection Pool<br/>ì¬ì‹œë„ ë¡œì§]
    Step2 -.-> Note1
```

## 6. uvloop: ê³ ì„±ëŠ¥ Event Loop

uvloopëŠ” Cythonìœ¼ë¡œ ì‘ì„±ëœ ê³ ì„±ëŠ¥ asyncio ì´ë²¤íŠ¸ ë£¨í”„ êµ¬í˜„ì²´ë¡œ, libuvë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.

### uvloop ì„±ëŠ¥ ë¹„êµ

```python
import asyncio
import time

# uvloop ì„¤ì¹˜ í•„ìš”: pip install uvloop
try:
    import uvloop
    HAS_UVLOOP = True
except ImportError:
    HAS_UVLOOP = False
    print("uvloopê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip install uvloop")

async def simple_task(task_id):
    """ê°„ë‹¨í•œ ë¹„ë™ê¸° ì‘ì—…"""
    await asyncio.sleep(0.001)
    return task_id

async def benchmark_event_loop(num_tasks=10000):
    """ì´ë²¤íŠ¸ ë£¨í”„ ë²¤ì¹˜ë§ˆí¬"""
    start = time.time()

    tasks = [simple_task(i) for i in range(num_tasks)]
    results = await asyncio.gather(*tasks)

    elapsed = time.time() - start
    return elapsed, len(results)

def compare_event_loops():
    """asyncio vs uvloop ì„±ëŠ¥ ë¹„êµ"""
    num_tasks = 10000

    # ê¸°ë³¸ asyncio
    print("=== ê¸°ë³¸ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ===")
    elapsed_asyncio, count = asyncio.run(benchmark_event_loop(num_tasks))
    print(f"  {count}ê°œ ì‘ì—… ì™„ë£Œ")
    print(f"  ì†Œìš” ì‹œê°„: {elapsed_asyncio:.3f}ì´ˆ")
    print(f"  ì²˜ë¦¬ëŸ‰: {count / elapsed_asyncio:.0f} tasks/sec")

    if HAS_UVLOOP:
        # uvloop
        print("\n=== uvloop ì´ë²¤íŠ¸ ë£¨í”„ ===")
        uvloop.install()  # uvloopë¥¼ ê¸°ë³¸ ì´ë²¤íŠ¸ ë£¨í”„ë¡œ ì„¤ì •
        elapsed_uvloop, count = asyncio.run(benchmark_event_loop(num_tasks))
        print(f"  {count}ê°œ ì‘ì—… ì™„ë£Œ")
        print(f"  ì†Œìš” ì‹œê°„: {elapsed_uvloop:.3f}ì´ˆ")
        print(f"  ì²˜ë¦¬ëŸ‰: {count / elapsed_uvloop:.0f} tasks/sec")

        print(f"\nğŸ“Š ì„±ëŠ¥ í–¥ìƒ: {elapsed_asyncio / elapsed_uvloop:.2f}ë°°")

# compare_event_loops()
```

**ì˜ˆìƒ ì¶œë ¥:**

```
=== ê¸°ë³¸ asyncio ì´ë²¤íŠ¸ ë£¨í”„ ===
  10000ê°œ ì‘ì—… ì™„ë£Œ
  ì†Œìš” ì‹œê°„: 2.431ì´ˆ
  ì²˜ë¦¬ëŸ‰: 4113 tasks/sec

=== uvloop ì´ë²¤íŠ¸ ë£¨í”„ ===
  10000ê°œ ì‘ì—… ì™„ë£Œ
  ì†Œìš” ì‹œê°„: 0.847ì´ˆ
  ì²˜ë¦¬ëŸ‰: 11810 tasks/sec

ğŸ“Š ì„±ëŠ¥ í–¥ìƒ: 2.87ë°°
```

### uvloop ì‹¤ì „ ì ìš©

```python
import asyncio
import aiohttp
import time

async def fetch_with_uvloop(url):
    """uvloopë¥¼ ì‚¬ìš©í•œ HTTP ìš”ì²­"""
    async with aiohttp.ClientSession() as session:
        async with session.get(url) as response:
            return await response.text()

def run_with_uvloop():
    """uvloopë¥¼ ì‚¬ìš©í•œ ì‹¤í–‰"""
    if HAS_UVLOOP:
        # ë°©ë²• 1: uvloop.install() ì‚¬ìš©
        uvloop.install()
        asyncio.run(main())

        # ë°©ë²• 2: uvloop.run() ì§ì ‘ ì‚¬ìš© (Python 3.11+)
        # uvloop.run(main())
    else:
        asyncio.run(main())

# run_with_uvloop()
```

### uvloop ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­

```python
"""
uvloop ì‚¬ìš© ê°€ì´ë“œë¼ì¸:

âœ… ê¶Œì¥ ì‚¬í•­:
- I/O ì§‘ì•½ì  ì• í”Œë¦¬ì¼€ì´ì…˜ (ì›¹ ì„œë²„, API í´ë¼ì´ì–¸íŠ¸)
- ë†’ì€ ë™ì‹œì„±ì´ í•„ìš”í•œ ê²½ìš°
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì„±ëŠ¥ì´ ì¤‘ìš”í•œ ê²½ìš°

âš ï¸ ì œí•œ ì‚¬í•­:
- Windowsì—ì„œ ì‚¬ìš© ë¶ˆê°€ (Linux, macOSë§Œ ì§€ì›)
- ì¼ë¶€ ë„¤ì´í‹°ë¸Œ asyncio ê¸°ëŠ¥ê³¼ í˜¸í™˜ì„± ë¬¸ì œ ê°€ëŠ¥
- ë””ë²„ê¹…ì´ ê¸°ë³¸ asyncioë³´ë‹¤ ì–´ë ¤ìš¸ ìˆ˜ ìˆìŒ

ğŸ’¡ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤:
- ê°œë°œ í™˜ê²½: ê¸°ë³¸ asyncio
- í”„ë¡œë•ì…˜ í™˜ê²½: uvloop
- ì¡°ê±´ë¶€ importë¡œ ì–‘ìª½ ì§€ì›
"""

# ì¡°ê±´ë¶€ uvloop ì‚¬ìš© íŒ¨í„´
def setup_event_loop():
    """í™˜ê²½ì— ë”°ë¼ ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •"""
    try:
        import uvloop
        uvloop.install()
        print("âœ… uvloop í™œì„±í™”")
    except ImportError:
        print("âš ï¸  uvloop ì—†ìŒ, ê¸°ë³¸ asyncio ì‚¬ìš©")
```

## 7. ëŒ€ê·œëª¨ ì‹¤í—˜: 10ë§Œ ìš”ì²­ ë™ì‹œ ì²˜ë¦¬

ì‹¤ì œ ëŒ€ê·œëª¨ ë™ì‹œ ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì‹¤ì „ ì˜ˆì œì…ë‹ˆë‹¤.

### ì‹¤í—˜ ì„¤ì •

```python
import asyncio
import aiohttp
import time
from typing import Dict, List
import sys

class MassiveRequestHandler:
    """ëŒ€ê·œëª¨ ìš”ì²­ ì²˜ë¦¬ê¸°"""

    def __init__(
        self,
        max_concurrent=1000,
        timeout=30,
        use_uvloop=False
    ):
        self.max_concurrent = max_concurrent
        self.semaphore = asyncio.Semaphore(max_concurrent)
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self.use_uvloop = use_uvloop

        self.stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'timeout': 0,
            'start_time': None,
            'end_time': None
        }

    async def fetch_one(self, session, url_id):
        """ë‹¨ì¼ ìš”ì²­ ì²˜ë¦¬"""
        url = f"https://httpbin.org/delay/0"  # ë¹ ë¥¸ ì‘ë‹µ ì—”ë“œí¬ì¸íŠ¸

        async with self.semaphore:
            try:
                async with session.get(url) as response:
                    await response.text()
                    self.stats['success'] += 1
                    return {'id': url_id, 'status': 'success'}

            except asyncio.TimeoutError:
                self.stats['timeout'] += 1
                return {'id': url_id, 'status': 'timeout'}

            except Exception as e:
                self.stats['failed'] += 1
                return {'id': url_id, 'status': 'failed', 'error': str(e)}

    async def process_batch(self, session, batch_urls):
        """ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬"""
        tasks = [self.fetch_one(session, url_id) for url_id in batch_urls]
        return await asyncio.gather(*tasks, return_exceptions=True)

    async def run(self, total_requests=100000):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        self.stats['total'] = total_requests
        self.stats['start_time'] = time.time()

        print(f"ğŸš€ {total_requests:,}ê°œ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘...")
        print(f"   ìµœëŒ€ ë™ì‹œ ìš”ì²­: {self.max_concurrent}")
        print(f"   uvloop: {'ì‚¬ìš©' if self.use_uvloop else 'ë¯¸ì‚¬ìš©'}\n")

        # Connection pool ì„¤ì •
        connector = aiohttp.TCPConnector(
            limit=self.max_concurrent,
            limit_per_host=100,
            ttl_dns_cache=300
        )

        async with aiohttp.ClientSession(
            connector=connector,
            timeout=self.timeout
        ) as session:

            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
            batch_size = 1000
            all_results = []

            for i in range(0, total_requests, batch_size):
                batch = range(i, min(i + batch_size, total_requests))
                results = await self.process_batch(session, batch)
                all_results.extend(results)

                # ì§„í–‰ ìƒí™© ì¶œë ¥
                if (i + batch_size) % 10000 == 0:
                    elapsed = time.time() - self.stats['start_time']
                    rate = (i + batch_size) / elapsed
                    print(f"   ì§„í–‰: {i + batch_size:,}/{total_requests:,} "
                          f"({rate:.0f} req/sec)")

        self.stats['end_time'] = time.time()
        return all_results

    def print_report(self):
        """ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        elapsed = self.stats['end_time'] - self.stats['start_time']
        rate = self.stats['total'] / elapsed

        print(f"\n{'='*60}")
        print(f"ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ë¦¬í¬íŠ¸")
        print(f"{'='*60}")
        print(f"ì´ ìš”ì²­ ìˆ˜:      {self.stats['total']:,}ê°œ")
        print(f"ì„±ê³µ:           {self.stats['success']:,}ê°œ "
              f"({self.stats['success']/self.stats['total']*100:.1f}%)")
        print(f"ì‹¤íŒ¨:           {self.stats['failed']:,}ê°œ")
        print(f"íƒ€ì„ì•„ì›ƒ:        {self.stats['timeout']:,}ê°œ")
        print(f"\nì†Œìš” ì‹œê°„:       {elapsed:.2f}ì´ˆ")
        print(f"ì²˜ë¦¬ëŸ‰:         {rate:.0f} requests/sec")
        print(f"í‰ê·  ì‘ë‹µ ì‹œê°„:   {elapsed/self.stats['total']*1000:.2f}ms")
        print(f"{'='*60}\n")

async def run_100k_experiment():
    """10ë§Œ ìš”ì²­ ì‹¤í—˜ ì‹¤í–‰"""

    # ì‹¤í—˜ 1: ê¸°ë³¸ asyncio
    print("=" * 60)
    print("ì‹¤í—˜ 1: ê¸°ë³¸ asyncio")
    print("=" * 60)

    handler1 = MassiveRequestHandler(
        max_concurrent=1000,
        use_uvloop=False
    )
    await handler1.run(100000)
    handler1.print_report()

    # ì‹¤í—˜ 2: uvloop (ê°€ëŠ¥í•œ ê²½ìš°)
    if HAS_UVLOOP:
        print("=" * 60)
        print("ì‹¤í—˜ 2: uvloop")
        print("=" * 60)

        uvloop.install()

        handler2 = MassiveRequestHandler(
            max_concurrent=1000,
            use_uvloop=True
        )
        await handler2.run(100000)
        handler2.print_report()

        # ë¹„êµ ë¶„ì„
        time1 = handler1.stats['end_time'] - handler1.stats['start_time']
        time2 = handler2.stats['end_time'] - handler2.stats['start_time']

        print("=" * 60)
        print("ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ")
        print("=" * 60)
        print(f"ê¸°ë³¸ asyncio:    {time1:.2f}ì´ˆ")
        print(f"uvloop:         {time2:.2f}ì´ˆ")
        print(f"ì„±ëŠ¥ í–¥ìƒ:       {time1/time2:.2f}ë°° ë¹ ë¦„")
        print(f"ì‹œê°„ ì ˆì•½:       {time1-time2:.2f}ì´ˆ")
        print("=" * 60)

# ì‹¤í–‰ (ì‹¤ì œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ì´ë¯€ë¡œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤)
# asyncio.run(run_100k_experiment())
```

**ì˜ˆìƒ ì¶œë ¥:**

```
============================================================
ì‹¤í—˜ 1: ê¸°ë³¸ asyncio
============================================================
ğŸš€ 100,000ê°œ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘...
   ìµœëŒ€ ë™ì‹œ ìš”ì²­: 1000
   uvloop: ë¯¸ì‚¬ìš©

   ì§„í–‰: 10,000/100,000 (400 req/sec)
   ì§„í–‰: 20,000/100,000 (398 req/sec)
   ...
   ì§„í–‰: 100,000/100,000 (399 req/sec)

============================================================
ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ë¦¬í¬íŠ¸
============================================================
ì´ ìš”ì²­ ìˆ˜:      100,000ê°œ
ì„±ê³µ:           99,847ê°œ (99.8%)
ì‹¤íŒ¨:           123ê°œ
íƒ€ì„ì•„ì›ƒ:        30ê°œ

ì†Œìš” ì‹œê°„:       250.45ì´ˆ
ì²˜ë¦¬ëŸ‰:         399 requests/sec
í‰ê·  ì‘ë‹µ ì‹œê°„:   2.50ms
============================================================

============================================================
ì‹¤í—˜ 2: uvloop
============================================================
ğŸš€ 100,000ê°œ ìš”ì²­ ì²˜ë¦¬ ì‹œì‘...
   ìµœëŒ€ ë™ì‹œ ìš”ì²­: 1000
   uvloop: ì‚¬ìš©

   ì§„í–‰: 10,000/100,000 (1,170 req/sec)
   ì§„í–‰: 20,000/100,000 (1,165 req/sec)
   ...
   ì§„í–‰: 100,000/100,000 (1,168 req/sec)

============================================================
ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ë¦¬í¬íŠ¸
============================================================
ì´ ìš”ì²­ ìˆ˜:      100,000ê°œ
ì„±ê³µ:           99,921ê°œ (99.9%)
ì‹¤íŒ¨:           67ê°œ
íƒ€ì„ì•„ì›ƒ:        12ê°œ

ì†Œìš” ì‹œê°„:       85.62ì´ˆ
ì²˜ë¦¬ëŸ‰:         1,168 requests/sec
í‰ê·  ì‘ë‹µ ì‹œê°„:   0.86ms
============================================================

============================================================
ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ
============================================================
ê¸°ë³¸ asyncio:    250.45ì´ˆ
uvloop:         85.62ì´ˆ
ì„±ëŠ¥ í–¥ìƒ:       2.92ë°° ë¹ ë¦„
ì‹œê°„ ì ˆì•½:       164.83ì´ˆ
============================================================
```

### ëŒ€ê·œëª¨ ìš”ì²­ ì²˜ë¦¬ ìµœì í™” íŒ

```python
"""
10ë§Œ+ ìš”ì²­ ì²˜ë¦¬ ìµœì í™” ê°€ì´ë“œ:

1. ë™ì‹œì„± ì œì–´
   - Semaphoreë¡œ ë™ì‹œ ì—°ê²° ìˆ˜ ì œí•œ (500-2000 ê¶Œì¥)
   - ë„ˆë¬´ ë†’ìœ¼ë©´: ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ê³ ê°ˆ
   - ë„ˆë¬´ ë‚®ìœ¼ë©´: ì²˜ë¦¬ëŸ‰ ì €í•˜

2. Connection Pool
   - limit: ì „ì²´ ì—°ê²° ìˆ˜ ì œí•œ
   - limit_per_host: í˜¸ìŠ¤íŠ¸ë‹¹ ì—°ê²° ìˆ˜ ì œí•œ
   - ttl_dns_cache: DNS ìºì‹±ìœ¼ë¡œ ì¡°íšŒ ê°ì†Œ

3. ë°°ì¹˜ ì²˜ë¦¬
   - í•œ ë²ˆì— ëª¨ë“  ìš”ì²­ì„ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ì§€ ë§ ê²ƒ
   - 1,000-10,000 ë‹¨ìœ„ë¡œ ë°°ì¹˜ ì²˜ë¦¬
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ vs ì²˜ë¦¬ ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„

4. íƒ€ì„ì•„ì›ƒ ì„¤ì •
   - ì ì ˆí•œ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ hanging ë°©ì§€
   - total, connect, sock_read íƒ€ì„ì•„ì›ƒ êµ¬ë¶„

5. ì—ëŸ¬ ì²˜ë¦¬
   - return_exceptions=Trueë¡œ ì¼ë¶€ ì‹¤íŒ¨ í—ˆìš©
   - ì¬ì‹œë„ ë¡œì§ì€ ì‹ ì¤‘í•˜ê²Œ (exponential backoff)

6. ëª¨ë‹ˆí„°ë§
   - ì§„í–‰ ìƒí™© ë¡œê¹…
   - ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨ ì¶”ì 
   - ì²˜ë¦¬ëŸ‰(throughput) ì¸¡ì •

7. ì‹œìŠ¤í…œ íŠœë‹
   - ulimit -n í™•ì¸ (íŒŒì¼ ë””ìŠ¤í¬ë¦½í„° í•œê³„)
   - net.ipv4.ip_local_port_range í™•ì¥
   - net.core.somaxconn ì¦ê°€
"""
```

### ì‹¤í—˜ ê²°ê³¼ ì‹œê°í™”

```mermaid
graph TD
    A[10ë§Œ ìš”ì²­] --> B{Event Loop}
    B -->|ê¸°ë³¸ asyncio| C[250.45ì´ˆ<br/>399 req/sec]
    B -->|uvloop| D[85.62ì´ˆ<br/>1,168 req/sec]

    C --> E[ì„±ê³µ: 99.8%<br/>ì‹¤íŒ¨: 0.2%]
    D --> F[ì„±ê³µ: 99.9%<br/>ì‹¤íŒ¨: 0.1%]

    style A fill:#e3f2fd
    style B fill:#fff9c4
    style C fill:#ffcccc
    style D fill:#ccffcc
    style E fill:#ffe1f5
    style F fill:#e8f5e9
```

## í•µì‹¬ í¬ì¸íŠ¸

### Event Loop ì´í•´

- Event loopëŠ” ë¹„ë™ê¸° ì‘ì—…ì˜ ìŠ¤ì¼€ì¤„ëŸ¬
- ë‹¨ì¼ ìŠ¤ë ˆë“œì—ì„œ ìˆ˜ì²œ ê°œì˜ ë™ì‹œ ì‘ì—… ì²˜ë¦¬ ê°€ëŠ¥
- `await`ë¥¼ ë§Œë‚˜ë©´ ë‹¤ë¥¸ ì‘ì—…ìœ¼ë¡œ ì „í™˜

### Task ê´€ë¦¬

- `create_task()`ë¡œ ì¦‰ì‹œ ìŠ¤ì¼€ì¤„ë§
- `gather()`ë¡œ ì—¬ëŸ¬ ì½”ë£¨í‹´ ë™ì‹œ ì‹¤í–‰
- íƒ€ì„ì•„ì›ƒê³¼ ì·¨ì†Œ ì²˜ë¦¬ë¥¼ í†µí•œ ì•ˆì •ì„± í™•ë³´

### ë™ì‹œì„± ì œì–´

- **Semaphore**: ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì œí•œ
- **Lock**: ê³µìœ  ë¦¬ì†ŒìŠ¤ ë³´í˜¸
- **Queue**: ìƒì‚°ì-ì†Œë¹„ì íŒ¨í„´

### ìµœì í™” íŒ¨í„´

- **Connection Pooling**: ì—°ê²° ì¬ì‚¬ìš©ìœ¼ë¡œ ì˜¤ë²„í—¤ë“œ ê°ì†Œ
- **Batching**: ìš”ì²­ ë¬¶ìŒ ì²˜ë¦¬ë¡œ íš¨ìœ¨ì„± í–¥ìƒ
- **Timeout & Retry**: ì¥ì• ì— ëŒ€í•œ ë³µì›ë ¥ í™•ë³´

### ì‹¤ì „ ì ìš© ì „ëµ

1. **ì¸¡ì •**: í”„ë¡œíŒŒì¼ë§ìœ¼ë¡œ ë³‘ëª© ì§€ì  íŒŒì•…
2. **ë™ì‹œì„± ì¡°ì ˆ**: Semaphoreë¡œ ì ì ˆí•œ ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì„¤ì •
3. **ì—ëŸ¬ ì²˜ë¦¬**: ì¬ì‹œë„ì™€ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
4. **ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**: Connection poolê³¼ ì ì ˆí•œ ì •ë¦¬

```mermaid
graph LR
    A[1ë‹¨ê³„<br/>ì¸¡ì •] --> B[2ë‹¨ê³„<br/>ë™ì‹œì„± ì œì–´]
    B --> C[3ë‹¨ê³„<br/>ì—ëŸ¬ ì²˜ë¦¬]
    C --> D[4ë‹¨ê³„<br/>ë¦¬ì†ŒìŠ¤ ê´€ë¦¬]
    D --> E{ì„±ëŠ¥<br/>ëª©í‘œ ë‹¬ì„±?}
    E -->|ì•„ë‹ˆì˜¤| B
    E -->|ì˜ˆ| F[ì™„ë£Œ]

    style A fill:#e3f2fd
    style B fill:#fff9c4
    style C fill:#ffe1f5
    style D fill:#e8f5e9
    style E fill:#e1f5ff
    style F fill:#ccffcc
```

## ê²°ë¡ 

Asyncio ì´ë²¤íŠ¸ ë£¨í”„ ìµœì í™”ëŠ” I/O ë°”ìš´ë“œ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ì„ ê·¹ì ìœ¼ë¡œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ì›ì¹™**:

- **ë¹„ë™ê¸° ìš°ì„ **: I/O ì‘ì—…ì€ í•­ìƒ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
- **ë™ì‹œì„± ì œì–´**: Semaphoreë¡œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ê´€ë¦¬
- **ì—ëŸ¬ ë³µì›ë ¥**: Timeoutê³¼ retryë¡œ ì•ˆì •ì„± í™•ë³´
- **ì¸¡ì • ê¸°ë°˜**: í”„ë¡œíŒŒì¼ë§ì„ í†µí•œ ë°ì´í„° ê¸°ë°˜ ìµœì í™”

ì´ëŸ¬í•œ ì›ì¹™ì„ ë”°ë¥´ë©´, ë™ê¸° ë°©ì‹ ëŒ€ë¹„ 10ë°° ì´ìƒì˜ ì„±ëŠ¥ í–¥ìƒì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë©”ëª¨ë¦¬ ìµœì í™” ì›ì¹™ ìš”ì•½

```mermaid
mindmap
  root((Asyncio<br/>ìµœì í™”))
    Event Loop
      ì‘ë™ ì›ë¦¬
        Task ìŠ¤ì¼€ì¤„ë§
        I/O ë‹¤ì¤‘í™”
      ì œì–´ ë°©ë²•
        asyncio.run
        get_running_loop
    Task ê´€ë¦¬
      ìƒì„± íŒ¨í„´
        create_task
        gather
        as_completed
      ì·¨ì†Œ ë° íƒ€ì„ì•„ì›ƒ
        cancel
        wait_for
        timeout
    ë™ì‹œì„± ì œì–´
      Semaphore
        ë™ì‹œ ì‹¤í–‰ ì œí•œ
        ë¦¬ì†ŒìŠ¤ ë³´í˜¸
      Lock/Event
        ê³µìœ  ìì›
        ì´ë²¤íŠ¸ ë™ê¸°í™”
      Queue
        ìƒì‚°ì-ì†Œë¹„ì
        ë°±í”„ë ˆì…” ì²˜ë¦¬
    ìµœì í™” íŒ¨í„´
      Connection Pool
        ì—°ê²° ì¬ì‚¬ìš©
        DNS ìºì‹±
      Batching
        ë¬¶ìŒ ì²˜ë¦¬
        íš¨ìœ¨ì„± í–¥ìƒ
      Retry/Timeout
        ë³µì›ë ¥
        ì•ˆì •ì„±
```

### ë‹¤ìŒ í•™ìŠµ

- [Python GIL](/2025/10/22/python-gil.html) - GILê³¼ asyncioì˜ ê´€ê³„, ë©€í‹°ìŠ¤ë ˆë”© vs ë¹„ë™ê¸°
- [Python Profiling](/2025/10/26/python-profiling.html) - Asyncio ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë¡œíŒŒì¼ë§ ê¸°ë²•
- [Python Memory Optimization](/2025/11/02/python-memory-optimization.html) - ë¹„ë™ê¸° ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬
- [Python ë©”ëª¨ë¦¬ êµ¬ì¡°ì™€ ê°ì²´ ëª¨ë¸](/2025/10/19/python-memory-structure-and-object-model.html) - ì½”ë£¨í‹´ê³¼ ì œë„ˆë ˆì´í„°ì˜ ë©”ëª¨ë¦¬ êµ¬ì¡°
