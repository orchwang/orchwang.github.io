---
layout: post
title: "Django ì™€ Celery ë¥¼ ì´ìš©í•œ ëŒ€ê·œëª¨ ì‘ì—… ë¶„ì‚°ì²˜ë¦¬"
date: 2025-11-10
categories: [Technology, Python]
tags: [python, celery, amqp]
published: true
excerpt: "Djangoì™€ Celeryë¥¼ í™œìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ì‚° ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ê³¼ AMQP ë©”ì‹œì§€ ë¸Œë¡œì»¤ë¥¼ í†µí•œ ë¹„ë™ê¸° ì‘ì—… ê´€ë¦¬ ê¸°ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤."
---

<div class="post-summary-box" markdown="1">

### ğŸ“‹ ì´ ê¸€ì—ì„œ ë‹¤ë£¨ëŠ” ë‚´ìš©

- **Celery ê¸°ë³¸ ê°œë…**: ë¶„ì‚° ì‘ì—… í ì‹œìŠ¤í…œì˜ ì•„í‚¤í…ì²˜ì™€ êµ¬ì„± ìš”ì†Œ
- **ë„ì… ì‹œì  ê²°ì •**: ì–¸ì œ Celery + AMQPë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•˜ëŠ” 8ê°€ì§€ ì²´í¬ë¦¬ìŠ¤íŠ¸
- **Django í”„ë¡œì íŠ¸ ì„¤ì •**: Redis/RabbitMQ ë¸Œë¡œì»¤ ì„¤ì •ê³¼ Celery ì•± êµ¬ì„±
- **ì‘ì—… ë¶„ì‚° íŒ¨í„´**: Chunking, Chain, Chord, ìš°ì„ ìˆœìœ„ í í™œìš©ë²•
- **ì‹¤ì „ ì˜ˆì œ**: 100ë§Œ ëª…ì—ê²Œ í‘¸ì‹œ ì•Œë¦¼ì„ ë°œì†¡í•˜ëŠ” ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ êµ¬í˜„
- **í”„ë¡œë•ì…˜ ë°°í¬**: Supervisor, ëª¨ë‹ˆí„°ë§, ë¡œê¹…, ë³´ì•ˆ ì„¤ì •
- **ì„±ëŠ¥ ìµœì í™”**: Database ìµœì í™”, ë©”ëª¨ë¦¬ ê´€ë¦¬, Rate Limiting

**ì˜ˆìƒ ì†Œìš” ì‹œê°„:** 30-40ë¶„ | **ë‚œì´ë„:** ì¤‘ê¸‰ | **ì‹¤ìŠµ í¬í•¨:** ì˜ˆ

</div>

## Introduction

ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ë‹¤ ë³´ë©´ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ë“¤ì„ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ê²½ìš°ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬, ì´ë©”ì¼ ë°œì†¡, ë°ì´í„° ë¶„ì„, ë¦¬í¬íŠ¸ ìƒì„± ë“±ì˜ ì‘ì—…ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ëŒ€í•œ ì‘ë‹µ ì‹œê°„ì„ ì§€ì—°ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

CeleryëŠ” Python ê¸°ë°˜ì˜ ë¶„ì‚° ì‘ì—… í ì‹œìŠ¤í…œìœ¼ë¡œ, Djangoì™€ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ë¬´ê±°ìš´ ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì¤ë‹ˆë‹¤. ì´ ê¸€ì—ì„œëŠ” Djangoì™€ Celeryë¥¼ ì´ìš©í•œ ëŒ€ê·œëª¨ ì‘ì—… ë¶„ì‚°ì²˜ë¦¬ ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

## Celery ë€?

CeleryëŠ” ë¶„ì‚° ë©”ì‹œì§€ ì „ë‹¬ì„ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ëŠ” ë¹„ë™ê¸° ì‘ì—… íì…ë‹ˆë‹¤. ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

- **ë¹„ë™ê¸° ì²˜ë¦¬**: ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
- **ë¶„ì‚° ì²˜ë¦¬**: ì—¬ëŸ¬ ì›Œì»¤(worker)ë¥¼ í†µí•´ ì‘ì—…ì„ ë¶„ì‚° ì‹¤í–‰
- **ìŠ¤ì¼€ì¤„ë§**: ì£¼ê¸°ì ì¸ ì‘ì—…(cron-like) ì‹¤í–‰ ì§€ì›
- **ì¬ì‹œë„ ë° ì—ëŸ¬ ì²˜ë¦¬**: ì‹¤íŒ¨í•œ ì‘ì—…ì— ëŒ€í•œ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
- **ëª¨ë‹ˆí„°ë§**: Flower ë“±ì„ í†µí•œ ì‹¤ì‹œê°„ ì‘ì—… ëª¨ë‹ˆí„°ë§

### Celery ì•„í‚¤í…ì²˜

```mermaid
graph LR
    A[Django App<br/>Producer] -->|1. Task ì „ì†¡| B[Message Broker<br/>RabbitMQ/Redis]
    B -->|2. Task ì „ë‹¬| C[Worker<br/>Process]
    C -->|3. ì‘ì—… ì²˜ë¦¬| D[Task Execution]
    D -->|4. ê²°ê³¼ ì €ì¥| E[Result Backend<br/>Optional]
    E -.->|5. ê²°ê³¼ ì¡°íšŒ| A

    style A fill:#e1f5ff
    style B fill:#fff4e1
    style C fill:#e8f5e9
    style D fill:#f3e5f5
    style E fill:#fce4ec
```

**ì£¼ìš” êµ¬ì„± ìš”ì†Œ:**

- **Producer**: ì‘ì—…ì„ ìƒì„±í•˜ê³  ë©”ì‹œì§€ ë¸Œë¡œì»¤ë¡œ ì „ì†¡ (Django ì•±)
- **Message Broker**: ì‘ì—… ë©”ì‹œì§€ë¥¼ íì— ì €ì¥ (RabbitMQ, Redis ë“±)
- **Worker**: íì—ì„œ ì‘ì—…ì„ ê°€ì ¸ì™€ ì‹¤í–‰
- **Result Backend**: ì‘ì—… ê²°ê³¼ë¥¼ ì €ì¥ (ì„ íƒì )

## Celery + AMQP ë„ì…ì„ ê³ ë ¤í•´ì•¼ í•˜ëŠ” ì‹œì 

Celeryì™€ AMQP (RabbitMQ) ì¡°í•©ì€ ê°•ë ¥í•˜ì§€ë§Œ, ëª¨ë“  í”„ë¡œì íŠ¸ì— í•„ìš”í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤. ë‹¤ìŒ ìƒí™©ì—ì„œ ë„ì…ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.

### ë„ì…í•´ì•¼ í•˜ëŠ” ê²½ìš°

**1. ì‚¬ìš©ì ìš”ì²­ ì‘ë‹µ ì‹œê°„ì´ ì¤‘ìš”í•œ ê²½ìš°**

```python
# ë¬¸ì œ ìƒí™©: ë™ê¸° ì²˜ë¦¬ë¡œ ì¸í•œ ëŠë¦° ì‘ë‹µ
def send_welcome_email(request):
    user = request.user
    # ì´ë©”ì¼ ë°œì†¡ì— 3-5ì´ˆ ì†Œìš”
    send_mail(
        'Welcome!',
        'Thank you for signing up.',
        'from@example.com',
        [user.email],
    )
    return JsonResponse({'status': 'ok'})  # ì‚¬ìš©ìëŠ” 5ì´ˆ ëŒ€ê¸°

# í•´ê²°: Celeryë¡œ ë¹„ë™ê¸° ì²˜ë¦¬
@shared_task
def send_welcome_email_task(user_id):
    user = User.objects.get(id=user_id)
    send_mail(...)

def send_welcome_email(request):
    send_welcome_email_task.delay(request.user.id)
    return JsonResponse({'status': 'ok'})  # ì¦‰ì‹œ ì‘ë‹µ (< 100ms)
```

**ì ìš© ê¸°ì¤€:**

- HTTP ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ 500msë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°
- ì‚¬ìš©ìê°€ ì¦‰ê°ì ì¸ í”¼ë“œë°±ì„ ê¸°ëŒ€í•˜ëŠ” ì‘ì—…
- íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¸í•œ ìš”ì²­ ì‹¤íŒ¨ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°

**2. ëŒ€ëŸ‰ì˜ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ê²½ìš°**

```python
# ì‹œë‚˜ë¦¬ì˜¤: 1ë§Œ ê°œì˜ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•
images = Image.objects.filter(status='pending')  # 10,000ê°œ

# ë™ê¸° ì²˜ë¦¬: 10,000 Ã— 2ì´ˆ = ì•½ 5.5ì‹œê°„
for image in images:
    resize_image(image)

# Celery ë³‘ë ¬ ì²˜ë¦¬: 20 ì›Œì»¤ ì‚¬ìš© ì‹œ ì•½ 16ë¶„
for image in images:
    resize_image_task.delay(image.id)
```

**ì ìš© ê¸°ì¤€:**

- ë™ì¼í•œ ì‘ì—…ì„ ìˆ˜ì²œ~ìˆ˜ë§Œ ë²ˆ ë°˜ë³µí•´ì•¼ í•˜ëŠ” ê²½ìš°
- ì‘ì—… ê°„ ì˜ì¡´ì„±ì´ ì—†ì–´ ë³‘ë ¬ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•œ ê²½ìš°
- ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•´ì•¼ í•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ìš”êµ¬ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°

**3. ì™¸ë¶€ API í˜¸ì¶œì´ ë¹ˆë²ˆí•œ ê²½ìš°**

```python
# ë¬¸ì œ: ì™¸ë¶€ API í˜¸ì¶œë¡œ ì¸í•œ ë¸”ë¡œí‚¹
def process_payment(request):
    # ê²°ì œ ê²Œì´íŠ¸ì›¨ì´ API í˜¸ì¶œ (2-3ì´ˆ)
    payment_result = stripe.charge.create(...)

    # SMS ë°œì†¡ API í˜¸ì¶œ (1-2ì´ˆ)
    send_sms(user.phone, "Payment confirmed")

    # íšŒê³„ ì‹œìŠ¤í…œ API í˜¸ì¶œ (1-2ì´ˆ)
    accounting_system.record_transaction(...)

    return response  # ì´ 4-7ì´ˆ ì†Œìš”

# í•´ê²°: API í˜¸ì¶œì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
@shared_task
def process_payment_async(payment_id):
    payment_result = stripe.charge.create(...)
    send_sms_task.delay(...)
    record_transaction_task.delay(...)
```

**ì ìš© ê¸°ì¤€:**

- ì™¸ë¶€ API ì‘ë‹µ ì‹œê°„ì´ 1ì´ˆ ì´ìƒì¸ ê²½ìš°
- API íƒ€ì„ì•„ì›ƒì´ë‚˜ ì¥ì• ê°€ ì‚¬ìš©ì ê²½í—˜ì— ì˜í–¥ì„ ì£¼ëŠ” ê²½ìš°
- Rate limitìœ¼ë¡œ ì¸í•´ ìš”ì²­ ì†ë„ ì¡°ì ˆì´ í•„ìš”í•œ ê²½ìš°

**4. ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•´ì•¼ í•˜ëŠ” ì‘ì—…ì´ ìˆëŠ” ê²½ìš°**

```python
# Celery Beatìœ¼ë¡œ ìŠ¤ì¼€ì¤„ë§
CELERY_BEAT_SCHEDULE = {
    'cleanup-old-sessions': {
        'task': 'myapp.tasks.cleanup_old_sessions',
        'schedule': crontab(hour=3, minute=0),  # ë§¤ì¼ ìƒˆë²½ 3ì‹œ
    },
    'send-daily-report': {
        'task': 'myapp.tasks.send_daily_report',
        'schedule': crontab(hour=9, minute=0, day_of_week='1-5'),  # í‰ì¼ 9ì‹œ
    },
    'update-cache': {
        'task': 'myapp.tasks.update_cache',
        'schedule': 300.0,  # 5ë¶„ë§ˆë‹¤
    },
}
```

**ì ìš© ê¸°ì¤€:**

- cron ì‘ì—…ì„ Python ì½”ë“œë¡œ ê´€ë¦¬í•˜ê³  ì‹¶ì€ ê²½ìš°
- ì‘ì—… ì‹¤í–‰ ì´ë ¥ê³¼ ê²°ê³¼ë¥¼ ì¶”ì í•´ì•¼ í•˜ëŠ” ê²½ìš°
- ì‘ì—… ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ë‚˜ ì•Œë¦¼ì´ í•„ìš”í•œ ê²½ìš°

**5. ë©”ì‹œì§€ ìœ ì‹¤ì„ ë°©ì§€í•´ì•¼ í•˜ëŠ” ì¤‘ìš”í•œ ì‘ì—…**

AMQP (RabbitMQ)ëŠ” ë©”ì‹œì§€ ì˜ì†ì„±ê³¼ ì•ˆì •ì„±ì´ ë›°ì–´ë‚˜ë¯€ë¡œ ì¤‘ìš”í•œ ì‘ì—…ì— ì í•©í•©ë‹ˆë‹¤.

```python
# RabbitMQ ì„¤ì •: ë©”ì‹œì§€ ì˜ì†ì„± ë³´ì¥
CELERY_BROKER_URL = 'amqp://localhost'
CELERY_TASK_ACKS_LATE = True  # ì‘ì—… ì™„ë£Œ í›„ ACK
CELERY_TASK_REJECT_ON_WORKER_LOST = True  # ì›Œì»¤ ì¥ì•  ì‹œ ì¬ì‹¤í–‰

@shared_task(bind=True, max_retries=5)
def process_payment(self, payment_id):
    try:
        # ì¤‘ìš”í•œ ê²°ì œ ì²˜ë¦¬
        payment = Payment.objects.get(id=payment_id)
        result = gateway.process(payment)
        payment.status = 'completed'
        payment.save()
    except Exception as exc:
        # ì¬ì‹œë„
        raise self.retry(exc=exc, countdown=60)
```

**ì ìš© ê¸°ì¤€:**

- ê¸ˆìœµ ê±°ë˜, ì£¼ë¬¸ ì²˜ë¦¬ ë“± ë°ì´í„° ë¬´ê²°ì„±ì´ ì¤‘ìš”í•œ ê²½ìš°
- ì‘ì—… ìœ ì‹¤ì´ ë¹„ì¦ˆë‹ˆìŠ¤ì— ì‹¬ê°í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²½ìš°
- ì›Œì»¤ ì¥ì•  ì‹œì—ë„ ì‘ì—…ì´ ì¬ì‹¤í–‰ë˜ì–´ì•¼ í•˜ëŠ” ê²½ìš°

**6. ìš°ì„ ìˆœìœ„ê°€ ë‹¤ë¥¸ ì‘ì—…ë“¤ì„ ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ê²½ìš°**

```python
# ìš°ì„ ìˆœìœ„ë³„ í ë¶„ë¦¬
CELERY_TASK_ROUTES = {
    'myapp.tasks.send_urgent_alert': {'queue': 'critical'},
    'myapp.tasks.process_order': {'queue': 'high'},
    'myapp.tasks.generate_report': {'queue': 'normal'},
    'myapp.tasks.cleanup_data': {'queue': 'low'},
}

# ì›Œì»¤ë¥¼ ìš°ì„ ìˆœìœ„ë³„ë¡œ ì‹¤í–‰
# Critical: ì¦‰ì‹œ ì²˜ë¦¬ (concurrency=5)
celery -A myproject worker -Q critical --concurrency=5

# High: ë¹ ë¥¸ ì²˜ë¦¬ (concurrency=10)
celery -A myproject worker -Q high --concurrency=10

# Normal/Low: ì—¬ìœ  ìˆì„ ë•Œ ì²˜ë¦¬ (concurrency=3)
celery -A myproject worker -Q normal,low --concurrency=3
```

**ì ìš© ê¸°ì¤€:**

- ê¸´ê¸‰í•œ ì‘ì—…(ì•Œë¦¼)ê³¼ ì¼ë°˜ ì‘ì—…(ë¦¬í¬íŠ¸)ì„ êµ¬ë¶„í•´ì•¼ í•˜ëŠ” ê²½ìš°
- ì¤‘ìš”ë„ì— ë”°ë¼ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¨ë“± ë°°ë¶„í•´ì•¼ í•˜ëŠ” ê²½ìš°
- íŠ¹ì • ì‘ì—…ì´ ë‹¤ë¥¸ ì‘ì—…ì„ ë¸”ë¡œí‚¹í•˜ì§€ ì•Šì•„ì•¼ í•˜ëŠ” ê²½ìš°

### ë„ì…í•˜ì§€ ì•Šì•„ë„ ë˜ëŠ” ê²½ìš°

**1. ì‘ì—…ì´ ê°„ë‹¨í•˜ê³  ë¹ ë¥¸ ê²½ìš°**

- ëª¨ë“  ì‘ì—…ì´ 100ms ì´ë‚´ì— ì™„ë£Œë˜ëŠ” ê²½ìš°
- ë™ê¸° ì²˜ë¦¬ë¡œë„ ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²½ìš°

**2. íŠ¸ë˜í”½ì´ ë§¤ìš° ë‚®ì€ ê²½ìš°**

- ì¼ì¼ ì‚¬ìš©ìê°€ ìˆ˜ì‹­ ëª… ì´í•˜ì¸ ë‚´ë¶€ ë„êµ¬
- MVP ë‹¨ê³„ì˜ í”„ë¡œí† íƒ€ì… ê°œë°œ

**3. ì¸í”„ë¼ ê´€ë¦¬ ë¶€ë‹´ì´ í° ê²½ìš°**

- ì†Œê·œëª¨ íŒ€ì—ì„œ ì¶”ê°€ ì„œë²„ ê´€ë¦¬ê°€ ì–´ë ¤ìš´ ê²½ìš°
- í´ë¼ìš°ë“œ ë¹„ìš©ì„ ìµœì†Œí™”í•´ì•¼ í•˜ëŠ” ê²½ìš°
- ëŒ€ì•ˆ: Django-Q (ë‹¨ìˆœí•œ ì‘ì—… í), Huey (ê²½ëŸ‰ ì‘ì—… í)

**4. ì‹¤ì‹œê°„ ê²°ê³¼ê°€ í•„ìš”í•œ ê²½ìš°**

- ì‚¬ìš©ìê°€ ì‘ì—… ê²°ê³¼ë¥¼ ì¦‰ì‹œ í™•ì¸í•´ì•¼ í•˜ëŠ” ê²½ìš°
- ì‘ì—… ì™„ë£Œ ì „ê¹Œì§€ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ìˆ˜ ì—†ëŠ” ê²½ìš°
- ëŒ€ì•ˆ: WebSocket, Server-Sent Eventsë¡œ ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸

### Redis vs RabbitMQ ì„ íƒ ê¸°ì¤€

**Redisë¥¼ ì„ íƒí•´ì•¼ í•˜ëŠ” ê²½ìš°:**

- ê°„ë‹¨í•œ ì‘ì—… íê°€ í•„ìš”í•œ ê²½ìš°
- ë†’ì€ ì²˜ë¦¬ ì†ë„ê°€ ì¤‘ìš”í•œ ê²½ìš°
- ì‘ì—… ìœ ì‹¤ì´ ì¹˜ëª…ì ì´ì§€ ì•Šì€ ê²½ìš°
- Redisë¥¼ ì´ë¯¸ ìºì‹œë¡œ ì‚¬ìš©í•˜ê³  ìˆëŠ” ê²½ìš°

```python
# Redis ì„¤ì •: ê°„ë‹¨í•˜ê³  ë¹ ë¦„
CELERY_BROKER_URL = 'redis://localhost:6379/0'
CELERY_RESULT_BACKEND = 'redis://localhost:6379/1'
```

**RabbitMQ (AMQP)ë¥¼ ì„ íƒí•´ì•¼ í•˜ëŠ” ê²½ìš°:**

- ë©”ì‹œì§€ ì˜ì†ì„±ì´ ì¤‘ìš”í•œ ê²½ìš° (ê²°ì œ, ì£¼ë¬¸ ë“±)
- ë³µì¡í•œ ë¼ìš°íŒ…ì´ í•„ìš”í•œ ê²½ìš°
- ë†’ì€ ì•ˆì •ì„±ê³¼ ì‹ ë¢°ì„±ì´ ìš”êµ¬ë˜ëŠ” ê²½ìš°
- ëŒ€ê·œëª¨ ë¶„ì‚° ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê²½ìš°

```python
# RabbitMQ ì„¤ì •: ì•ˆì •ì ì´ê³  ì˜ì†ì 
CELERY_BROKER_URL = 'amqp://guest:guest@localhost:5672//'
CELERY_RESULT_BACKEND = 'rpc://'
CELERY_TASK_ACKS_LATE = True
```

### ë‹¨ê³„ì  ë„ì… ì „ëµ

**Phase 1: ì‘ì€ ê·œëª¨ë¡œ ì‹œì‘**

```python
# ê°€ì¥ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” 1-2ê°œ ì‘ì—…ë§Œ ë¨¼ì € ë¹„ë™ê¸°ë¡œ ì „í™˜
@shared_task
def send_email_task(subject, body, recipient):
    send_mail(subject, body, 'from@example.com', [recipient])

# ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ìµœì†Œí™”
def signup_view(request):
    # ... íšŒì›ê°€ì… ë¡œì§ ...
    send_email_task.delay('Welcome', 'Thank you', user.email)
```

**Phase 2: ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”**

```bash
# Flowerë¡œ ì‘ì—… ëª¨ë‹ˆí„°ë§
celery -A myproject flower

# ì„±ëŠ¥ ì§€í‘œ í™•ì¸
# - ì‘ì—… ì²˜ë¦¬ ì†ë„
# - ì‹¤íŒ¨ìœ¨
# - ëŒ€ê¸° í ê¸¸ì´
```

**Phase 3: í™•ì¥**

```python
# ë” ë§ì€ ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì „í™˜
# ìš°ì„ ìˆœìœ„ í ë„ì…
# ì›Œì»¤ ìˆ˜ ì¦ê°€
# ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼ ì²´ê³„ êµ¬ì¶•
```

### ë¹„ìš© vs íš¨ê³¼ ë¶„ì„

**ë„ì… ë¹„ìš©:**

- ì¸í”„ë¼ ë¹„ìš©: ë©”ì‹œì§€ ë¸Œë¡œì»¤ ì„œë²„, ì›Œì»¤ ì„œë²„ (ì›” $50-200)
- ê°œë°œ ì‹œê°„: ì´ˆê¸° ì„¤ì • ë° í•™ìŠµ (1-2ì£¼)
- ìš´ì˜ ë¶€ë‹´: ëª¨ë‹ˆí„°ë§, ì¥ì•  ëŒ€ì‘ (ì£¼ë‹¹ 2-3ì‹œê°„)

**ê¸°ëŒ€ íš¨ê³¼:**

- ì‘ë‹µ ì‹œê°„ ê°œì„ : 2-5ì´ˆ â†’ 100-200ms (10-50ë°° í–¥ìƒ)
- ì²˜ë¦¬ëŸ‰ ì¦ê°€: ìˆœì°¨ ì²˜ë¦¬ â†’ ë³‘ë ¬ ì²˜ë¦¬ (ì›Œì»¤ ìˆ˜ë§Œí¼ ë°°ìˆ˜ ì¦ê°€)
- ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ: ì¦‰ê°ì ì¸ í”¼ë“œë°±, íƒ€ì„ì•„ì›ƒ ì œê±°
- ì‹œìŠ¤í…œ ì•ˆì •ì„±: ì‘ì—… ê²©ë¦¬, ì—ëŸ¬ ì¬ì‹œë„, ë¶€í•˜ ë¶„ì‚°

### ì˜ì‚¬ê²°ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

ë‹¤ìŒ ì§ˆë¬¸ì— 3ê°œ ì´ìƒ "ì˜ˆ"ë¼ë©´ Celery + AMQP ë„ì…ì„ ê³ ë ¤í•˜ì„¸ìš”:

- [ ] HTTP ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì´ 1ì´ˆë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°ê°€ ìˆëŠ”ê°€?
- [ ] í•˜ë£¨ì— 1,000ê°œ ì´ìƒì˜ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ì´ í•„ìš”í•œê°€?
- [ ] ì™¸ë¶€ API í˜¸ì¶œì´ ì „ì²´ ë¡œì§ì˜ 30% ì´ìƒì„ ì°¨ì§€í•˜ëŠ”ê°€?
- [ ] ì£¼ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•´ì•¼ í•˜ëŠ” cron ì‘ì—…ì´ 5ê°œ ì´ìƒì¸ê°€?
- [ ] ì‘ì—… ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ê°€ í•„ìš”í•œê°€?
- [ ] ì‘ì—… ìš°ì„ ìˆœìœ„ë¥¼ êµ¬ë¶„í•´ì•¼ í•˜ëŠ”ê°€?
- [ ] íŒ€ì— ì¸í”„ë¼ ê´€ë¦¬ ì—­ëŸ‰ì´ ìˆëŠ”ê°€?
- [ ] ì„œë¹„ìŠ¤ í™•ì¥ ê³„íšì´ ìˆëŠ”ê°€?

## Django í”„ë¡œì íŠ¸ì— Celery ì„¤ì •í•˜ê¸°

### 1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install celery
pip install redis  # Redisë¥¼ ë¸Œë¡œì»¤ë¡œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
# ë˜ëŠ”
pip install amqp  # RabbitMQë¥¼ ë¸Œë¡œì»¤ë¡œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
```

### 2. Celery ì„¤ì • íŒŒì¼ ìƒì„±

**í”„ë¡œì íŠ¸ êµ¬ì¡°:**

```
myproject/
â”œâ”€â”€ myproject/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ celery.py  # ìƒˆë¡œ ìƒì„±
â”‚   â””â”€â”€ urls.py
â””â”€â”€ manage.py
```

**myproject/celery.py:**

```python
import os
from celery import Celery

# Django ì„¤ì • ëª¨ë“ˆ ì§€ì •
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'myproject.settings')

app = Celery('myproject')

# Django settingsì—ì„œ CELERY_ ì ‘ë‘ì‚¬ë¥¼ ê°€ì§„ ì„¤ì • ë¡œë“œ
app.config_from_object('django.conf:settings', namespace='CELERY')

# ë“±ë¡ëœ Django ì•±ì—ì„œ tasks.pyë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ ë¡œë“œ
app.autodiscover_tasks()

@app.task(bind=True, ignore_result=True)
def debug_task(self):
    print(f'Request: {self.request!r}')
```

**myproject/**init**.py:**

```python
# Celery ì•±ì´ Djangoì™€ í•¨ê»˜ ë¡œë“œë˜ë„ë¡ ì„¤ì •
from .celery import app as celery_app

__all__ = ('celery_app',)
```

### 3. Django settings.py ì„¤ì •

```python
# settings.py

# Celery Configuration
CELERY_BROKER_URL = 'redis://localhost:6379/0'  # Redis ì‚¬ìš© ì‹œ
# ë˜ëŠ”
# CELERY_BROKER_URL = 'amqp://guest:guest@localhost:5672//'  # RabbitMQ ì‚¬ìš© ì‹œ

CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'

CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'Asia/Seoul'

# ì‘ì—… ì‹œê°„ ì œí•œ (ì´ˆ)
CELERY_TASK_TIME_LIMIT = 30 * 60  # 30ë¶„
CELERY_TASK_SOFT_TIME_LIMIT = 25 * 60  # 25ë¶„

# ê²°ê³¼ ì €ì¥ ê¸°ê°„ (ì´ˆ)
CELERY_RESULT_EXPIRES = 3600  # 1ì‹œê°„
```

## Celery Task ì‘ì„±í•˜ê¸°

### ê¸°ë³¸ Task ì˜ˆì œ

**myapp/tasks.py:**

```python
from celery import shared_task
from django.core.mail import send_mail
from time import sleep

@shared_task
def send_email_task(subject, message, recipient_list):
    """ì´ë©”ì¼ ë°œì†¡ ì‘ì—…"""
    send_mail(
        subject,
        message,
        'from@example.com',
        recipient_list,
        fail_silently=False,
    )
    return f'Email sent to {len(recipient_list)} recipients'

@shared_task
def process_large_file(file_path):
    """ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ì‘ì—…"""
    # íŒŒì¼ ì²˜ë¦¬ ë¡œì§
    sleep(10)  # ì‹œë®¬ë ˆì´ì…˜
    return f'File {file_path} processed successfully'

@shared_task(bind=True, max_retries=3)
def retry_task(self, x, y):
    """ì¬ì‹œë„ ê°€ëŠ¥í•œ ì‘ì—…"""
    try:
        result = x / y
        return result
    except ZeroDivisionError as exc:
        # 10ì´ˆ í›„ ì¬ì‹œë„
        raise self.retry(exc=exc, countdown=10)
```

### Django Viewì—ì„œ Task í˜¸ì¶œ

```python
# views.py
from django.http import JsonResponse
from .tasks import send_email_task, process_large_file

def send_notification(request):
    # ë¹„ë™ê¸° ì‘ì—… ì‹¤í–‰
    task = send_email_task.delay(
        'Welcome!',
        'Thank you for joining.',
        ['user@example.com']
    )

    return JsonResponse({
        'status': 'Task submitted',
        'task_id': task.id
    })

def process_file(request):
    file_path = request.POST.get('file_path')

    # ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜í•˜ê³  ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
    task = process_large_file.delay(file_path)

    return JsonResponse({
        'status': 'Processing started',
        'task_id': task.id
    })
```

## ëŒ€ê·œëª¨ ì‘ì—… ë¶„ì‚°ì²˜ë¦¬ íŒ¨í„´

### 1. Chunking (ì‘ì—… ë¶„í• )

ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ ì‘ì€ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬:

```python
from celery import group

@shared_task
def process_batch(items):
    """ë°°ì¹˜ ë‹¨ìœ„ ì²˜ë¦¬"""
    results = []
    for item in items:
        # ê° ì•„ì´í…œ ì²˜ë¦¬
        result = process_single_item(item)
        results.append(result)
    return results

def process_large_dataset(dataset):
    """ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬"""
    chunk_size = 100
    chunks = [dataset[i:i+chunk_size] for i in range(0, len(dataset), chunk_size)]

    # ê° ì²­í¬ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    job = group(process_batch.s(chunk) for chunk in chunks)
    result = job.apply_async()

    return result
```

### 2. Chain (ì‘ì—… ì²´ì¸)

ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ì–´ì•¼ í•˜ëŠ” ì‘ì—…ë“¤:

```python
from celery import chain

@shared_task
def fetch_data(url):
    """ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    # API í˜¸ì¶œ ë“±
    return data

@shared_task
def transform_data(data):
    """ë°ì´í„° ë³€í™˜"""
    # ë°ì´í„° ì²˜ë¦¬
    return transformed_data

@shared_task
def save_data(data):
    """ë°ì´í„° ì €ì¥"""
    # DB ì €ì¥
    return 'Saved'

# ì²´ì¸ìœ¼ë¡œ ì—°ê²°
workflow = chain(
    fetch_data.s('https://api.example.com/data'),
    transform_data.s(),
    save_data.s()
)
result = workflow.apply_async()
```

### 3. Chord (ë³‘ë ¬ + ì§‘ê³„)

ì—¬ëŸ¬ ì‘ì—…ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ì§‘ê³„:

```python
from celery import chord

@shared_task
def process_item(item_id):
    """ê°œë³„ ì•„ì´í…œ ì²˜ë¦¬"""
    # ì²˜ë¦¬ ë¡œì§
    return result

@shared_task
def aggregate_results(results):
    """ê²°ê³¼ ì§‘ê³„"""
    total = sum(results)
    # ì§‘ê³„ ê²°ê³¼ ì €ì¥
    return total

# Chord íŒ¨í„´: ë³‘ë ¬ ì²˜ë¦¬ í›„ ì§‘ê³„
callback = aggregate_results.s()
header = [process_item.s(i) for i in range(100)]
result = chord(header)(callback)
```

### 4. ìš°ì„ ìˆœìœ„ í

ì¤‘ìš”ë„ì— ë”°ë¥¸ ì‘ì—… ì²˜ë¦¬:

```mermaid
graph TB
    subgraph "Django Application"
        A1[ê¸´ê¸‰ ì•Œë¦¼ ì‘ì—…]
        A2[ì¼ë°˜ ì‘ì—…]
        A3[ë°°ì¹˜ ì‘ì—…]
    end

    subgraph "Message Broker - Queue System"
        B1[High Priority Queue]
        B2[Default Queue]
        B3[Low Priority Queue]
    end

    subgraph "Worker Pool"
        C1[Worker 1-10<br/>concurrency=10]
        C2[Worker 11-30<br/>concurrency=20]
        C3[Worker 31-35<br/>concurrency=5]
    end

    A1 -->|urgent_task| B1
    A2 -->|normal_task| B2
    A3 -->|batch_task| B3

    B1 -->|ì¦‰ì‹œ ì²˜ë¦¬| C1
    B2 -->|ë¹ ë¥¸ ì²˜ë¦¬| C2
    B3 -->|ì—¬ìœ  ìˆì„ ë•Œ| C3

    style B1 fill:#ffcdd2
    style B2 fill:#fff9c4
    style B3 fill:#c8e6c9
    style C1 fill:#ffebee
    style C2 fill:#fffde7
    style C3 fill:#e8f5e9
```

**ì½”ë“œ êµ¬í˜„:**

```python
# settings.py
CELERY_TASK_ROUTES = {
    'myapp.tasks.urgent_task': {'queue': 'high_priority'},
    'myapp.tasks.normal_task': {'queue': 'default'},
    'myapp.tasks.batch_task': {'queue': 'low_priority'},
}

# tasks.py
@shared_task
def urgent_task():
    """ê¸´ê¸‰ ì‘ì—…"""
    pass

# Worker ì‹¤í–‰ ì‹œ í ì§€ì •
# celery -A myproject worker -Q high_priority
# celery -A myproject worker -Q default,low_priority
```

## ì‹¤ì „ ì˜ˆì œ: ëŒ€ê·œëª¨ ì•± í‘¸ì‹œ ì•Œë¦¼ ì‹œìŠ¤í…œ

ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œ ìˆ˜ì‹­ë§Œ~ìˆ˜ë°±ë§Œ ëª…ì˜ ì‚¬ìš©ìì—ê²Œ í‘¸ì‹œ ì•Œë¦¼ì„ ë°œì†¡í•´ì•¼ í•˜ëŠ” ê²½ìš°ë¥¼ ìƒê°í•´ë´…ì‹œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ì»¤ë¨¸ìŠ¤ ì•±ì—ì„œ íŠ¹ê°€ ì´ë²¤íŠ¸ ì•Œë¦¼, ê²Œì„ ì•±ì—ì„œ ì—…ë°ì´íŠ¸ ê³µì§€, ë‰´ìŠ¤ ì•±ì—ì„œ ì†ë³´ ì „ì†¡ ë“±ì˜ ìƒí™©ì…ë‹ˆë‹¤.

### ì „ì²´ ì›Œí¬í”Œë¡œìš°

```mermaid
graph TD
    A[Admin: ìº í˜ì¸ ìƒì„±] -->|API í˜¸ì¶œ| B[Django View]
    B -->|execute_push_campaign.delay| C[Celery Broker]
    C -->|ì‘ì—… ë¶„ë°°| D[Main Task: execute_push_campaign]
    D -->|1M ë””ë°”ì´ìŠ¤ ì¡°íšŒ| E[Database]
    D -->|500ê°œì”© ë¶„í• | F[2,000ê°œ ë°°ì¹˜ ìƒì„±]
    F -->|Chord íŒ¨í„´| G{Worker Pool<br/>20-50 workers}

    G -->|ë°°ì¹˜ 1-500| H1[send_push_batch]
    G -->|ë°°ì¹˜ 501-1000| H2[send_push_batch]
    G -->|ë°°ì¹˜ N| H3[send_push_batch]

    H1 -->|FCM API| I[Firebase Cloud Messaging]
    H2 -->|FCM API| I
    H3 -->|FCM API| I

    I -->|í‘¸ì‹œ ë°œì†¡| J[ì‚¬ìš©ì ë””ë°”ì´ìŠ¤]

    H1 -->|ê²°ê³¼| K[aggregate_campaign_results]
    H2 -->|ê²°ê³¼| K
    H3 -->|ê²°ê³¼| K

    K -->|í†µê³„ ì—…ë°ì´íŠ¸| E
    K -->|ì™„ë£Œ ì•Œë¦¼| L[ê´€ë¦¬ì ì•Œë¦¼]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style F fill:#fce4ec
    style G fill:#fff9c4
    style I fill:#ffebee
    style K fill:#e0f2f1
```

### ì‹œë‚˜ë¦¬ì˜¤

**ìš”êµ¬ì‚¬í•­:**

- 100ë§Œ ëª…ì˜ ì‚¬ìš©ìì—ê²Œ ë™ì‹œì— í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡
- FCM (Firebase Cloud Messaging) ì‚¬ìš©
- ë°œì†¡ ì„±ê³µ/ì‹¤íŒ¨ ì¶”ì 
- ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ì²˜ë¦¬ (ê¸´ê¸‰ ê³µì§€ vs ì¼ë°˜ ë§ˆì¼€íŒ…)
- Rate limiting (FCM API ì œí•œ ì¤€ìˆ˜)
- ì¬ì‹œë„ ë¡œì§
- ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§

### ë°ì´í„° ëª¨ë¸ ì„¤ê³„

```python
# models.py
from django.db import models
from django.contrib.auth.models import User

class DeviceToken(models.Model):
    """ì‚¬ìš©ì ë””ë°”ì´ìŠ¤ í† í°"""
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name='devices')
    token = models.CharField(max_length=255, unique=True)
    platform = models.CharField(max_length=10, choices=[
        ('ios', 'iOS'),
        ('android', 'Android'),
    ])
    is_active = models.BooleanField(default=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        indexes = [
            models.Index(fields=['is_active', 'platform']),
        ]

class PushCampaign(models.Model):
    """í‘¸ì‹œ ìº í˜ì¸"""
    PRIORITY_CHOICES = [
        ('high', 'ê¸´ê¸‰'),
        ('normal', 'ì¼ë°˜'),
        ('low', 'ë§ˆì¼€íŒ…'),
    ]

    STATUS_CHOICES = [
        ('draft', 'ì¤€ë¹„ ì¤‘'),
        ('scheduled', 'ì˜ˆì•½ë¨'),
        ('processing', 'ë°œì†¡ ì¤‘'),
        ('completed', 'ì™„ë£Œ'),
        ('failed', 'ì‹¤íŒ¨'),
    ]

    title = models.CharField(max_length=100)
    message = models.TextField()
    priority = models.CharField(max_length=10, choices=PRIORITY_CHOICES, default='normal')
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='draft')

    # ë°œì†¡ ëŒ€ìƒ
    target_user_ids = models.JSONField(default=list, blank=True)  # íŠ¹ì • ì‚¬ìš©ì
    target_all = models.BooleanField(default=False)  # ì „ì²´ ì‚¬ìš©ì

    # í†µê³„
    total_recipients = models.IntegerField(default=0)
    sent_count = models.IntegerField(default=0)
    success_count = models.IntegerField(default=0)
    failure_count = models.IntegerField(default=0)

    # ë©”íƒ€ë°ì´í„°
    data_payload = models.JSONField(default=dict, blank=True)  # ì¶”ê°€ ë°ì´í„°
    scheduled_at = models.DateTimeField(null=True, blank=True)
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)

    created_at = models.DateTimeField(auto_now_add=True)
    created_by = models.ForeignKey(User, on_delete=models.SET_NULL, null=True)

class PushLog(models.Model):
    """í‘¸ì‹œ ë°œì†¡ ë¡œê·¸"""
    campaign = models.ForeignKey(PushCampaign, on_delete=models.CASCADE, related_name='logs')
    device_token = models.ForeignKey(DeviceToken, on_delete=models.CASCADE)

    STATUS_CHOICES = [
        ('pending', 'ëŒ€ê¸° ì¤‘'),
        ('sent', 'ë°œì†¡ë¨'),
        ('failed', 'ì‹¤íŒ¨'),
        ('invalid_token', 'ìœ íš¨í•˜ì§€ ì•Šì€ í† í°'),
    ]

    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='pending')
    error_message = models.TextField(blank=True)
    sent_at = models.DateTimeField(null=True, blank=True)

    class Meta:
        indexes = [
            models.Index(fields=['campaign', 'status']),
        ]
```

### Celery Task êµ¬í˜„

```python
# notifications/tasks.py
from celery import shared_task, group, chord
from firebase_admin import messaging
from django.utils import timezone
from django.db.models import F
from .models import PushCampaign, DeviceToken, PushLog
import logging

logger = logging.getLogger(__name__)

# FCM API Rate Limit: ì´ˆë‹¹ 600ê°œ ìš”ì²­
BATCH_SIZE = 500  # í•œ ë²ˆì— ì²˜ë¦¬í•  ë””ë°”ì´ìŠ¤ ìˆ˜
RATE_LIMIT = '600/m'  # ë¶„ë‹¹ 600ê°œ ì œí•œ


@shared_task(bind=True, max_retries=3, rate_limit=RATE_LIMIT)
def send_push_batch(self, campaign_id, device_token_ids):
    """
    ë°°ì¹˜ ë‹¨ìœ„ë¡œ í‘¸ì‹œ ì•Œë¦¼ ë°œì†¡

    Args:
        campaign_id: ìº í˜ì¸ ID
        device_token_ids: ë””ë°”ì´ìŠ¤ í† í° ID ë¦¬ìŠ¤íŠ¸ (ìµœëŒ€ 500ê°œ)
    """
    try:
        campaign = PushCampaign.objects.get(id=campaign_id)
        device_tokens = DeviceToken.objects.filter(
            id__in=device_token_ids,
            is_active=True
        ).select_related('user')

        # FCM ë©”ì‹œì§€ êµ¬ì„±
        messages = []
        token_map = {}  # ì¸ë±ìŠ¤ -> device_token ë§¤í•‘

        for idx, device in enumerate(device_tokens):
            token_map[idx] = device

            message = messaging.Message(
                notification=messaging.Notification(
                    title=campaign.title,
                    body=campaign.message,
                ),
                data=campaign.data_payload,
                token=device.token,
                android=messaging.AndroidConfig(
                    priority='high' if campaign.priority == 'high' else 'normal',
                ),
                apns=messaging.APNSConfig(
                    headers={
                        'apns-priority': '10' if campaign.priority == 'high' else '5',
                    },
                ),
            )
            messages.append(message)

        # FCM Batch ì „ì†¡
        response = messaging.send_all(messages)

        # ê²°ê³¼ ì²˜ë¦¬
        success_count = 0
        failure_count = 0
        invalid_tokens = []

        for idx, resp in enumerate(response.responses):
            device = token_map[idx]

            if resp.success:
                # ì„±ê³µ
                PushLog.objects.create(
                    campaign=campaign,
                    device_token=device,
                    status='sent',
                    sent_at=timezone.now()
                )
                success_count += 1
            else:
                # ì‹¤íŒ¨
                error_code = resp.exception.code if resp.exception else 'unknown'

                # ìœ íš¨í•˜ì§€ ì•Šì€ í† í° ì²˜ë¦¬
                if error_code in ['invalid-argument', 'registration-token-not-registered']:
                    invalid_tokens.append(device.id)
                    PushLog.objects.create(
                        campaign=campaign,
                        device_token=device,
                        status='invalid_token',
                        error_message=str(resp.exception)
                    )
                else:
                    PushLog.objects.create(
                        campaign=campaign,
                        device_token=device,
                        status='failed',
                        error_message=str(resp.exception)
                    )

                failure_count += 1

        # ìœ íš¨í•˜ì§€ ì•Šì€ í† í° ë¹„í™œì„±í™”
        if invalid_tokens:
            DeviceToken.objects.filter(id__in=invalid_tokens).update(is_active=False)

        # ìº í˜ì¸ í†µê³„ ì—…ë°ì´íŠ¸
        campaign.sent_count = F('sent_count') + len(device_token_ids)
        campaign.success_count = F('success_count') + success_count
        campaign.failure_count = F('failure_count') + failure_count
        campaign.save(update_fields=['sent_count', 'success_count', 'failure_count'])

        logger.info(
            f'Batch sent for campaign {campaign_id}: '
            f'{success_count} success, {failure_count} failed'
        )

        return {
            'campaign_id': campaign_id,
            'total': len(device_token_ids),
            'success': success_count,
            'failure': failure_count,
        }

    except Exception as exc:
        logger.error(f'Error sending push batch: {exc}')
        # ì¬ì‹œë„ (ìµœëŒ€ 3ë²ˆ)
        raise self.retry(exc=exc, countdown=60 * (self.request.retries + 1))


@shared_task
def aggregate_campaign_results(results, campaign_id):
    """
    ëª¨ë“  ë°°ì¹˜ ì‘ì—… ì™„ë£Œ í›„ ìµœì¢… ì§‘ê³„

    Args:
        results: ê° ë°°ì¹˜ ì‘ì—…ì˜ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        campaign_id: ìº í˜ì¸ ID
    """
    campaign = PushCampaign.objects.get(id=campaign_id)

    # ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
    campaign.status = 'completed'
    campaign.completed_at = timezone.now()
    campaign.save(update_fields=['status', 'completed_at'])

    # í†µê³„ ë¡œê¹…
    logger.info(
        f'Campaign {campaign_id} completed: '
        f'{campaign.success_count}/{campaign.total_recipients} sent successfully'
    )

    # ê´€ë¦¬ìì—ê²Œ ì™„ë£Œ ì•Œë¦¼ (ì„ íƒì‚¬í•­)
    send_admin_notification.delay(campaign_id)

    return {
        'campaign_id': campaign_id,
        'status': 'completed',
        'total': campaign.total_recipients,
        'success': campaign.success_count,
        'failure': campaign.failure_count,
    }


@shared_task
def send_admin_notification(campaign_id):
    """ê´€ë¦¬ìì—ê²Œ ìº í˜ì¸ ì™„ë£Œ ì•Œë¦¼"""
    campaign = PushCampaign.objects.get(id=campaign_id)

    # ì´ë©”ì¼ì´ë‚˜ ìŠ¬ë™ ì•Œë¦¼ ë°œì†¡
    # send_email(...) or send_slack_message(...)

    logger.info(f'Admin notification sent for campaign {campaign_id}')


@shared_task
def execute_push_campaign(campaign_id):
    """
    í‘¸ì‹œ ìº í˜ì¸ ì‹¤í–‰ (ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)

    ì´ íƒœìŠ¤í¬ëŠ” ëŒ€ê·œëª¨ í‘¸ì‹œ ë°œì†¡ì„ ë‹¤ìŒê³¼ ê°™ì´ ì²˜ë¦¬í•©ë‹ˆë‹¤:
    1. ëŒ€ìƒ ì‚¬ìš©ìì˜ ë””ë°”ì´ìŠ¤ í† í° ì¡°íšŒ
    2. ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë¶„í•  (500ê°œì”©)
    3. ê° ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬
    4. ëª¨ë“  ë°°ì¹˜ ì™„ë£Œ í›„ ê²°ê³¼ ì§‘ê³„
    """
    try:
        campaign = PushCampaign.objects.get(id=campaign_id)

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        campaign.status = 'processing'
        campaign.started_at = timezone.now()
        campaign.save(update_fields=['status', 'started_at'])

        # ëŒ€ìƒ ë””ë°”ì´ìŠ¤ í† í° ì¡°íšŒ
        if campaign.target_all:
            # ì „ì²´ ì‚¬ìš©ì
            device_tokens = DeviceToken.objects.filter(is_active=True)
        else:
            # íŠ¹ì • ì‚¬ìš©ì
            device_tokens = DeviceToken.objects.filter(
                user_id__in=campaign.target_user_ids,
                is_active=True
            )

        # ì´ ìˆ˜ì‹ ì ìˆ˜ ì—…ë°ì´íŠ¸
        total_devices = device_tokens.count()
        campaign.total_recipients = total_devices
        campaign.save(update_fields=['total_recipients'])

        if total_devices == 0:
            campaign.status = 'completed'
            campaign.completed_at = timezone.now()
            campaign.save(update_fields=['status', 'completed_at'])
            return {'message': 'No recipients found'}

        # ë””ë°”ì´ìŠ¤ í† í° IDë¥¼ ë°°ì¹˜ë¡œ ë¶„í• 
        device_ids = list(device_tokens.values_list('id', flat=True))
        batches = [
            device_ids[i:i + BATCH_SIZE]
            for i in range(0, len(device_ids), BATCH_SIZE)
        ]

        logger.info(
            f'Starting campaign {campaign_id}: '
            f'{total_devices} devices in {len(batches)} batches'
        )

        # Chord íŒ¨í„´: ëª¨ë“  ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ ì§‘ê³„
        callback = aggregate_campaign_results.s(campaign_id)
        header = group(
            send_push_batch.s(campaign_id, batch)
            for batch in batches
        )

        # ì‘ì—… ì‹¤í–‰
        chord(header)(callback)

        return {
            'campaign_id': campaign_id,
            'total_recipients': total_devices,
            'batches': len(batches),
            'status': 'processing'
        }

    except PushCampaign.DoesNotExist:
        logger.error(f'Campaign {campaign_id} not found')
        raise
    except Exception as exc:
        logger.error(f'Error executing campaign {campaign_id}: {exc}')
        campaign.status = 'failed'
        campaign.save(update_fields=['status'])
        raise
```

### Django View & API êµ¬í˜„

```python
# notifications/views.py
from rest_framework import viewsets, status
from rest_framework.decorators import action
from rest_framework.response import Response
from rest_framework.permissions import IsAdminUser
from django.utils import timezone
from .models import PushCampaign
from .tasks import execute_push_campaign
from .serializers import PushCampaignSerializer


class PushCampaignViewSet(viewsets.ModelViewSet):
    """í‘¸ì‹œ ìº í˜ì¸ ê´€ë¦¬ API"""
    queryset = PushCampaign.objects.all()
    serializer_class = PushCampaignSerializer
    permission_classes = [IsAdminUser]

    def perform_create(self, serializer):
        """ìº í˜ì¸ ìƒì„±"""
        serializer.save(created_by=self.request.user)

    @action(detail=True, methods=['post'])
    def send(self, request, pk=None):
        """
        ìº í˜ì¸ ë°œì†¡ ì‹œì‘

        POST /api/campaigns/{id}/send/
        """
        campaign = self.get_object()

        # ìƒíƒœ ê²€ì¦
        if campaign.status not in ['draft', 'scheduled']:
            return Response(
                {'error': 'Campaign already sent or in progress'},
                status=status.HTTP_400_BAD_REQUEST
            )

        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì ì ˆí•œ íë¡œ ë¼ìš°íŒ…
        queue_name = {
            'high': 'high_priority',
            'normal': 'default',
            'low': 'low_priority',
        }.get(campaign.priority, 'default')

        # ë¹„ë™ê¸° ì‘ì—… ì‹¤í–‰
        task = execute_push_campaign.apply_async(
            args=[campaign.id],
            queue=queue_name
        )

        return Response({
            'campaign_id': campaign.id,
            'task_id': task.id,
            'status': 'Campaign sending started',
            'priority': campaign.priority,
            'queue': queue_name,
        })

    @action(detail=True, methods=['get'])
    def stats(self, request, pk=None):
        """
        ìº í˜ì¸ í†µê³„ ì¡°íšŒ

        GET /api/campaigns/{id}/stats/
        """
        campaign = self.get_object()

        # ì§„í–‰ë¥  ê³„ì‚°
        progress = 0
        if campaign.total_recipients > 0:
            progress = (campaign.sent_count / campaign.total_recipients) * 100

        return Response({
            'campaign_id': campaign.id,
            'status': campaign.status,
            'total_recipients': campaign.total_recipients,
            'sent': campaign.sent_count,
            'success': campaign.success_count,
            'failure': campaign.failure_count,
            'progress': round(progress, 2),
            'started_at': campaign.started_at,
            'completed_at': campaign.completed_at,
        })

    @action(detail=False, methods=['get'])
    def active(self, request):
        """
        ì§„í–‰ ì¤‘ì¸ ìº í˜ì¸ ëª©ë¡

        GET /api/campaigns/active/
        """
        active_campaigns = self.queryset.filter(
            status='processing'
        ).order_by('-started_at')

        serializer = self.get_serializer(active_campaigns, many=True)
        return Response(serializer.data)
```

### Settings ì„¤ì •

```python
# settings.py

# Celery Task Routing (ìš°ì„ ìˆœìœ„ë³„ í)
CELERY_TASK_ROUTES = {
    'notifications.tasks.send_push_batch': {
        'queue': 'default',
        'routing_key': 'push.batch',
    },
    'notifications.tasks.execute_push_campaign': {
        'queue': 'default',
        'routing_key': 'push.campaign',
    },
}

# Rate Limiting ì„¤ì •
CELERY_TASK_ANNOTATIONS = {
    'notifications.tasks.send_push_batch': {
        'rate_limit': '600/m',  # FCM API ì œí•œ ì¤€ìˆ˜
    },
}

# Redisë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ ì €ì¥
CELERY_RESULT_BACKEND = 'redis://localhost:6379/1'
CELERY_RESULT_EXPIRES = 3600  # 1ì‹œê°„

# Worker ë™ì‹œì„± ì„¤ì •
CELERY_WORKER_PREFETCH_MULTIPLIER = 4
CELERY_WORKER_MAX_TASKS_PER_CHILD = 1000  # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€
```

### Worker ì‹¤í–‰ ì „ëµ

ëŒ€ê·œëª¨ í‘¸ì‹œ ë°œì†¡ì„ ìœ„í•œ ì›Œì»¤ êµ¬ì„±:

```bash
# ê³ ìš°ì„ ìˆœìœ„ í ì›Œì»¤ (ê¸´ê¸‰ ê³µì§€ìš©)
celery -A myproject worker \
    -Q high_priority \
    --concurrency=10 \
    -n worker-high@%h \
    -l info

# ì¼ë°˜ ìš°ì„ ìˆœìœ„ í ì›Œì»¤ (ì¼ë°˜ ì•Œë¦¼ìš©)
celery -A myproject worker \
    -Q default \
    --concurrency=20 \
    -n worker-normal@%h \
    -l info

# ì €ìš°ì„ ìˆœìœ„ í ì›Œì»¤ (ë§ˆì¼€íŒ…ìš©)
celery -A myproject worker \
    -Q low_priority \
    --concurrency=5 \
    -n worker-low@%h \
    -l info

# Autoscaleë¡œ ë™ì  ì¡°ì • (í”¼í¬ ì‹œê°„ ëŒ€ë¹„)
celery -A myproject worker \
    -Q default \
    --autoscale=50,10 \
    -n worker-autoscale@%h \
    -l info
```

### ì‚¬ìš© ì˜ˆì‹œ

```python
# ê´€ë¦¬ì í˜ì´ì§€ë‚˜ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ìº í˜ì¸ ìƒì„± ë° ë°œì†¡

# 1. ì „ì²´ ì‚¬ìš©ì ëŒ€ìƒ ê¸´ê¸‰ ê³µì§€
campaign = PushCampaign.objects.create(
    title='ê¸´ê¸‰ ì‹œìŠ¤í…œ ì ê²€ ì•ˆë‚´',
    message='ì˜¤ëŠ˜ ì˜¤í›„ 2ì‹œë¶€í„° 30ë¶„ê°„ ì‹œìŠ¤í…œ ì ê²€ì´ ì§„í–‰ë©ë‹ˆë‹¤.',
    priority='high',
    target_all=True,
    created_by=admin_user,
)
execute_push_campaign.delay(campaign.id)

# 2. íŠ¹ì • ì‚¬ìš©ì ëŒ€ìƒ ë§ˆì¼€íŒ…
vip_users = User.objects.filter(membership='VIP').values_list('id', flat=True)
campaign = PushCampaign.objects.create(
    title='VIP íšŒì› íŠ¹ë³„ í• ì¸',
    message='ì˜¤ëŠ˜ë§Œ 50% í• ì¸! ì§€ê¸ˆ ë°”ë¡œ í™•ì¸í•˜ì„¸ìš”.',
    priority='low',
    target_user_ids=list(vip_users),
    data_payload={'type': 'promotion', 'discount': 50},
    created_by=admin_user,
)
execute_push_campaign.delay(campaign.id)

# 3. APIë¥¼ í†µí•œ ë°œì†¡ (REST API í˜¸ì¶œ)
# POST /api/campaigns/{id}/send/
# GET /api/campaigns/{id}/stats/
```

### ì„±ëŠ¥ ìµœì í™” íŒ

**1. Database ìµœì í™”:**

```python
# Bulk Createë¡œ ë¡œê·¸ ìƒì„±
logs = [
    PushLog(campaign=campaign, device_token=device, status='sent')
    for device in devices
]
PushLog.objects.bulk_create(logs, batch_size=1000)

# Select Related/Prefetch Related í™œìš©
device_tokens = DeviceToken.objects.filter(
    user_id__in=user_ids
).select_related('user').only('id', 'token', 'platform')
```

**2. ë©”ëª¨ë¦¬ ê´€ë¦¬:**

```python
# Iteratorë¥¼ ì‚¬ìš©í•˜ì—¬ ëŒ€ëŸ‰ ì¿¼ë¦¬ ë©”ëª¨ë¦¬ ì ˆì•½
for device in DeviceToken.objects.filter(is_active=True).iterator(chunk_size=1000):
    process_device(device)
```

**3. ëª¨ë‹ˆí„°ë§:**

```python
# Flowerë¡œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
# http://localhost:5555

# Custom metrics (Prometheus + Grafana)
from prometheus_client import Counter, Histogram

push_sent_counter = Counter('push_notifications_sent', 'Push notifications sent')
push_duration = Histogram('push_batch_duration', 'Push batch processing duration')
```

### ì˜ˆìƒ ì²˜ë¦¬ëŸ‰ ê³„ì‚°

**ì‹œë‚˜ë¦¬ì˜¤: 100ë§Œ ëª… ì‚¬ìš©ìì—ê²Œ í‘¸ì‹œ ë°œì†¡**

- **ë°°ì¹˜ í¬ê¸°**: 500ê°œ
- **ì´ ë°°ì¹˜ ìˆ˜**: 2,000ê°œ
- **ì›Œì»¤ ìˆ˜**: 20ê°œ (concurrency=20)
- **Rate Limit**: ë¶„ë‹¹ 600ê°œ (ì´ˆë‹¹ 10ê°œ)
- **ì˜ˆìƒ ì²˜ë¦¬ ì‹œê°„**:
  - ì´ë¡ ì : (1,000,000 / 600) = ì•½ 1,667ë¶„ = 27.8ì‹œê°„
  - ì‹¤ì œ (20 ì›Œì»¤ ë³‘ë ¬): ì•½ 1.5~2ì‹œê°„
  - ìµœì í™” (50 ì›Œì»¤ ë³‘ë ¬): ì•½ 30~40ë¶„

**ì²˜ë¦¬ëŸ‰ í–¥ìƒ ë°©ë²•:**

- ì›Œì»¤ ìˆ˜ ì¦ê°€ (horizontal scaling)
- ì—¬ëŸ¬ FCM í”„ë¡œì íŠ¸ ì‚¬ìš© (rate limit ë¶„ì‚°)
- ë°°ì¹˜ í¬ê¸° ìµœì í™”
- ë„¤íŠ¸ì›Œí¬ I/O ìµœì í™”

ì´ êµ¬í˜„ì€ ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ëŒ€ê·œëª¨ í‘¸ì‹œ ì•Œë¦¼ì„ ì•ˆì •ì ìœ¼ë¡œ ë°œì†¡í•  ìˆ˜ ìˆëŠ” ê²¬ê³ í•œ ì‹œìŠ¤í…œì„ ì œê³µí•©ë‹ˆë‹¤.

## AMQPì™€ ë©”ì‹œì§€ ë¸Œë¡œì»¤

### RabbitMQ ì„¤ì •

RabbitMQëŠ” AMQP(Advanced Message Queuing Protocol)ë¥¼ êµ¬í˜„í•œ ë©”ì‹œì§€ ë¸Œë¡œì»¤ì…ë‹ˆë‹¤.

**ì„¤ì¹˜ ë° ì‹¤í–‰:**

```bash
# macOS
brew install rabbitmq
brew services start rabbitmq

# Ubuntu
sudo apt-get install rabbitmq-server
sudo systemctl start rabbitmq-server
```

**Django ì„¤ì •:**

```python
# settings.py
CELERY_BROKER_URL = 'amqp://guest:guest@localhost:5672//'
CELERY_RESULT_BACKEND = 'rpc://'

# RabbitMQ ì„¤ì • ìƒì„¸
CELERY_BROKER_CONNECTION_RETRY = True
CELERY_BROKER_CONNECTION_RETRY_ON_STARTUP = True
CELERY_BROKER_CONNECTION_MAX_RETRIES = 10
```

### Redis vs RabbitMQ

| íŠ¹ì§•          | Redis          | RabbitMQ           |
| ------------- | -------------- | ------------------ |
| í”„ë¡œí† ì½œ      | Redis Protocol | AMQP               |
| ë©”ì‹œì§€ ì˜ì†ì„± | ì œí•œì          | ê°•ë ¥í•¨             |
| ì„±ëŠ¥          | ë§¤ìš° ë¹ ë¦„      | ë¹ ë¦„               |
| ë³µì¡í•œ ë¼ìš°íŒ… | ì œí•œì          | ê°•ë ¥í•¨             |
| ë©”ëª¨ë¦¬ ì‚¬ìš©   | ë†’ìŒ           | ë‚®ìŒ               |
| ì‚¬ìš© ì‚¬ë¡€     | ê°„ë‹¨í•œ ì‘ì—… í | ë³µì¡í•œ ë©”ì‹œì§• íŒ¨í„´ |

## Celery Worker ì‹¤í–‰ ë° ê´€ë¦¬

### Worker ì‹¤í–‰

```bash
# ê¸°ë³¸ ì‹¤í–‰
celery -A myproject worker -l info

# ë™ì‹œì„± ì„¤ì • (ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜)
celery -A myproject worker -l info --concurrency=4

# íŠ¹ì • íë§Œ ì²˜ë¦¬
celery -A myproject worker -Q high_priority,default -l info

# Autoscale (ìµœì†Œ-ìµœëŒ€ ì›Œì»¤ ìˆ˜)
celery -A myproject worker --autoscale=10,3 -l info
```

### Celery Beat (ì£¼ê¸°ì  ì‘ì—…)

```bash
# Beat ìŠ¤ì¼€ì¤„ëŸ¬ ì‹¤í–‰
celery -A myproject beat -l info
```

**ì£¼ê¸°ì  ì‘ì—… ì„¤ì •:**

```python
# settings.py
from celery.schedules import crontab

CELERY_BEAT_SCHEDULE = {
    'send-daily-report': {
        'task': 'myapp.tasks.generate_daily_report',
        'schedule': crontab(hour=9, minute=0),  # ë§¤ì¼ ì˜¤ì „ 9ì‹œ
    },
    'cleanup-old-data': {
        'task': 'myapp.tasks.cleanup_old_data',
        'schedule': crontab(hour=2, minute=0, day_of_week=1),  # ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 2ì‹œ
    },
    'process-pending-jobs': {
        'task': 'myapp.tasks.process_pending_jobs',
        'schedule': 300.0,  # 5ë¶„ë§ˆë‹¤
    },
}
```

## ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬

### Flowerë¥¼ ì´ìš©í•œ ëª¨ë‹ˆí„°ë§

```bash
# Flower ì„¤ì¹˜
pip install flower

# Flower ì‹¤í–‰
celery -A myproject flower
# http://localhost:5555 ì—ì„œ ì ‘ê·¼
```

Flower ê¸°ëŠ¥:

- ì‹¤ì‹œê°„ ì‘ì—… ëª¨ë‹ˆí„°ë§
- ì›Œì»¤ ìƒíƒœ í™•ì¸
- ì‘ì—… í†µê³„ ë° ê·¸ë˜í”„
- ì‘ì—… ì¬ì‹œë„/ì·¨ì†Œ

### ì‘ì—… ìƒíƒœ í™•ì¸

```python
from celery.result import AsyncResult

def check_task_status(task_id):
    result = AsyncResult(task_id)

    return {
        'task_id': task_id,
        'status': result.status,
        'result': result.result if result.ready() else None,
        'traceback': result.traceback if result.failed() else None,
    }
```

## í”„ë¡œë•ì…˜ ë°°í¬ ê³ ë ¤ì‚¬í•­

### 1. Supervisorë¥¼ ì´ìš©í•œ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬

```ini
; /etc/supervisor/conf.d/celery.conf
[program:celery-worker]
command=/path/to/venv/bin/celery -A myproject worker -l info
directory=/path/to/project
user=www-data
numprocs=1
stdout_logfile=/var/log/celery/worker.log
stderr_logfile=/var/log/celery/worker_error.log
autostart=true
autorestart=true
startsecs=10
stopwaitsecs=600

[program:celery-beat]
command=/path/to/venv/bin/celery -A myproject beat -l info
directory=/path/to/project
user=www-data
numprocs=1
stdout_logfile=/var/log/celery/beat.log
stderr_logfile=/var/log/celery/beat_error.log
autostart=true
autorestart=true
startsecs=10
```

### 2. ë¡œê¹… ì„¤ì •

```python
# settings.py
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'handlers': {
        'celery': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': '/var/log/celery/celery.log',
            'maxBytes': 1024 * 1024 * 10,  # 10MB
            'backupCount': 5,
        },
    },
    'loggers': {
        'celery': {
            'handlers': ['celery'],
            'level': 'INFO',
        },
    },
}
```

### 3. ë³´ì•ˆ ì„¤ì •

```python
# settings.py

# ì‘ì—… ì§ë ¬í™” ì œí•œ (pickle ì‚¬ìš© ê¸ˆì§€)
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'

# ë¸Œë¡œì»¤ ì—°ê²° ë³´ì•ˆ
CELERY_BROKER_URL = 'amqps://user:password@hostname:5671//'
CELERY_BROKER_USE_SSL = {
    'keyfile': '/path/to/key.pem',
    'certfile': '/path/to/cert.pem',
    'ca_certs': '/path/to/ca.pem',
}
```

## Key Points

- **CeleryëŠ” Djangoì™€ í•¨ê»˜ ì‚¬ìš©í•˜ì—¬ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬**í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë„êµ¬ì…ë‹ˆë‹¤
- **Message Broker (Redis, RabbitMQ)**ë¥¼ í†µí•´ ì‘ì—…ì„ íì— ì €ì¥í•˜ê³  ì›Œì»¤ê°€ ì²˜ë¦¬í•©ë‹ˆë‹¤
- **Chunking, Chain, Chord** ë“±ì˜ íŒ¨í„´ì„ í™œìš©í•˜ì—¬ ëŒ€ê·œëª¨ ì‘ì—…ì„ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ì‚° ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ëŒ€ê·œëª¨ í‘¸ì‹œ ì•Œë¦¼ ì‹œìŠ¤í…œ**ê³¼ ê°™ì€ ì‹¤ì „ ì˜ˆì œì—ì„œ 100ë§Œ ëª… ì´ìƒì˜ ì‚¬ìš©ìì—ê²Œ íš¨ìœ¨ì ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ë°œì†¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **ìš°ì„ ìˆœìœ„ íì™€ Rate Limiting**ì„ í™œìš©í•˜ì—¬ ì™¸ë¶€ API ì œì•½ì‚¬í•­ì„ ì¤€ìˆ˜í•˜ë©´ì„œë„ ìµœì ì˜ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **Celery Beat**ì„ ì‚¬ìš©í•˜ì—¬ ì£¼ê¸°ì ì¸ ì‘ì—…ì„ ìŠ¤ì¼€ì¤„ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- **Flower**ë¥¼ í†µí•´ ì‘ì—… ì‹¤í–‰ ìƒíƒœë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” **Supervisor, ë¡œê¹…, ë³´ì•ˆ ì„¤ì •**ì„ ì ì ˆíˆ êµ¬ì„±í•´ì•¼ í•©ë‹ˆë‹¤
- **Database ìµœì í™” (bulk_create, select_related)ì™€ ë©”ëª¨ë¦¬ ê´€ë¦¬**ê°€ ëŒ€ê·œëª¨ ì²˜ë¦¬ì˜ í•µì‹¬ì…ë‹ˆë‹¤

## Conclusion

Djangoì™€ Celeryë¥¼ í™œìš©í•˜ë©´ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ê³¼ ì‚¬ìš©ì ê²½í—˜ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ë°±ê·¸ë¼ìš´ë“œë¡œ ë¶„ë¦¬í•¨ìœ¼ë¡œì¨ ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ìœ ì§€í•˜ê³ , ì—¬ëŸ¬ ì›Œì»¤ë¥¼ í†µí•œ ë¶„ì‚° ì²˜ë¦¬ë¡œ ëŒ€ê·œëª¨ ì‘ì—…ë„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Celeryë¥¼ ë„ì…í•  ë•ŒëŠ” ì‘ì—…ì˜ íŠ¹ì„±ì— ë§ëŠ” ë©”ì‹œì§€ ë¸Œë¡œì»¤ë¥¼ ì„ íƒí•˜ê³ , ì ì ˆí•œ ì‘ì—… ë¶„ì‚° íŒ¨í„´ì„ ì ìš©í•˜ë©°, ëª¨ë‹ˆí„°ë§ ì²´ê³„ë¥¼ êµ¬ì¶•í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

### Next Steps

- [Django REST Frameworkì™€ ë¹„ë™ê¸° API êµ¬í˜„]
- [RabbitMQ ê³ ê¸‰ ê¸°ëŠ¥ê³¼ ë©”ì‹œì§€ íŒ¨í„´]
- [Celery ì„±ëŠ¥ ìµœì í™” ë° íŠœë‹]
- [ë¶„ì‚° ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„]
